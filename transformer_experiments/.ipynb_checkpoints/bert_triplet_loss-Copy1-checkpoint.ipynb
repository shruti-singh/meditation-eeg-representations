{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/train.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = dataset[dataset[\"question1\"].isnull() == False]\n",
    "new_dataset = new_dataset[new_dataset[\"question2\"].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.to_csv(\"data/cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149263, 404287, 0.3692005926482919)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_dataset['is_duplicate'] == 1).sum(), new_dataset.shape[0], (new_dataset['is_duplicate'] == 1).sum()/new_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 290455)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset['question1']), len(new_dataset['question1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 299173)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset['question2']), len(new_dataset['question2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52269"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(new_dataset[\"question2\"].unique()).intersection(set(new_dataset[\"question1\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149596\n"
     ]
    }
   ],
   "source": [
    "unique_questions = {}\n",
    "ctr_idx= 0\n",
    "positive_pairs = []\n",
    "\n",
    "for row in new_dataset.iterrows():\n",
    "    if row[1]['is_duplicate'] == 1:\n",
    "        if not row[1]['question1'] in unique_questions:\n",
    "            unique_questions[row[1]['question1']] = ctr_idx\n",
    "            q1_id = ctr_idx\n",
    "            ctr_idx += 1\n",
    "        if not row[1]['question2'] in unique_questions:\n",
    "            unique_questions[row[1]['question2']] = ctr_idx\n",
    "            q2_id = ctr_idx\n",
    "            ctr_idx += 1\n",
    "        if q1_id != q2_id:\n",
    "            positive_pairs.append([unique_questions[row[1]['question1']], unique_questions[row[1]['question1']]])\n",
    "print(len(unique_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pair_dict = {}\n",
    "for i in positive_pairs:\n",
    "    pos_pair_dict[i[0]] = i[1]\n",
    "    pos_pair_dict[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_questions_rmap = {}\n",
    "for k,v in unique_questions.items():\n",
    "    unique_questions_rmap[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149596 149263\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_questions), len(positive_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149263\n"
     ]
    }
   ],
   "source": [
    "triplets = []\n",
    "\n",
    "for pair in positive_pairs:\n",
    "    while True:\n",
    "        negative = random.randint(0, len(unique_questions))\n",
    "        if negative == pair[0] or negative == pair[1] or pos_pair_dict[pair[1]] == negative or pos_pair_dict[pair[0]] == negative:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    triplets.append([pair[0], pair[1], negative])\n",
    "    \n",
    "print(len(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(triplets)\n",
    "len_80_20 = int(0.8 * len(triplets))\n",
    "train_triples = triplets[0:len_80_20]\n",
    "test_triples = triplets[len_80_20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404287 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404287 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[['question1', 'question2', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.concatenate((new_dataset[\"question1\"].to_numpy(), new_dataset[\"question2\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What is the step by step guide to invest in share market in india?',\n",
       "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       "       'How can I increase the speed of my internet connection while using a VPN?',\n",
       "       ..., \"What's this coin?\",\n",
       "       'I am having little hairfall problem but I want to use hair styling product. Which one should I prefer out of gel, wax and clay?',\n",
       "       'What is it like to have sex with your cousin?'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808574,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_text_using_bert(text):\n",
    "#     input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)  # Batch size 1\n",
    "#     outputs = model(input_ids.to('cuda'))\n",
    "#     last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
    "#     return last_hidden_states.cpu().mean(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_batch_using_bert(text_list):\n",
    "    input_ids = torch.tensor(tokenizer.batch_encode_plus(data_batch, pad_to_max_length=True)['input_ids'])\n",
    "    outputs = model(input_ids.to('cuda'))\n",
    "    last_hidden_states = outputs[0].cpu()  # The last hidden-state is the first element of the output tuple\n",
    "    \n",
    "    # return the vec of the CLS token\n",
    "    return last_hidden_states[:,0,:].detach().numpy()\n",
    "    \n",
    "    # return the mean of all token vecs\n",
    "    #return last_hidden_states.mean(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = [\"How can I increase the speed of my internet connection while using a VPN?\", \n",
    "              \"How can I increase the speed of my internet connection\"]\n",
    "\n",
    "vecs = embed_text_batch_using_bert(data_batch)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train-test data in the format of vocab id sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  qid1  qid2  \\\n",
       "0           0   0     1     2   \n",
       "1           1   1     3     4   \n",
       "2           2   2     5     6   \n",
       "3           3   3     7     8   \n",
       "4           4   4     9    10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2129, 2064, 1045, 3623, 1996, 3177, 1997, 2026, 4274, 4434]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_text = tokenizer.tokenize('How can I increase the speed of my internet connection')\n",
    "tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
       "          4434,  2096,  2478,  1037, 21210,  2078,  1029,   102],\n",
       "        [  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
       "          4434,   102,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenizer.batch_encode_plus(data_batch, pad_to_max_length=True)['input_ids'])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora custom dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset class needs to implement three functions: __init__, __len__, and __getitem__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraQuestionsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.question_tok_triples = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.question_tok_triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.question_tok_triples[idx]\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_triples[0:6400], batch_size=64, shuffle=True)\n",
    "# test_dataloader = DataLoader(train_triples[0:1600], batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with triplet margin loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TripletMarginLoss\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLNetwork(nn.Module):\n",
    "    def __init__(self, emb_dim=768):\n",
    "        super(CLNetwork, self).__init__()\n",
    "        #self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, 5),\n",
    "#             nn.PReLU(),\n",
    "#             nn.MaxPool2d(2, stride=2),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Conv2d(32, 64, 5),\n",
    "#             nn.PReLU(),\n",
    "#             nn.MaxPool2d(2, stride=2),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(64*4*4, 512),\n",
    "#             nn.PReLU(),\n",
    "#             nn.Linear(512, emb_dim)\n",
    "#         )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    torch.nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum()\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(anchor_out-anchor_out).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLNetwork(768)\n",
    "# model = torch.jit.script(model)#.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = TripletLoss()\n",
    "# criterion = torch.jit.script(TripletLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119410, 29853)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_triples), len(test_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(train_trip_toks[i][1]) for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_encode_plus??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1 #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trip_toks = []\n",
    "for trip in train_triples[0:144]:\n",
    "    data_batch = [unique_questions_rmap[trip[0]], unique_questions_rmap[trip[1]], unique_questions_rmap[trip[2]]]\n",
    "    train_trip_toks.append(torch.tensor(tokenizer.batch_encode_plus(data_batch, max_length=20, pad_to_max_length=True)['input_ids']))\n",
    "    \n",
    "train_ds = QuoraQuestionsDataset(train_trip_toks)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trip_toks = []\n",
    "for trip in test_triples[0:80]:\n",
    "    data_batch = [unique_questions_rmap[trip[0]], unique_questions_rmap[trip[1]], unique_questions_rmap[trip[2]]]\n",
    "    test_trip_toks.append(torch.tensor(tokenizer.batch_encode_plus(data_batch, max_length=20, pad_to_max_length=True)['input_ids']))\n",
    "\n",
    "test_ds = QuoraQuestionsDataset(test_trip_toks)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 3, 20])\n",
      "tensor([ 101, 2054, 2079, 2116, 2111, 6232, 4697, 4419, 2739, 1029,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]) tensor([ 101, 2054, 2079, 2116, 2111, 6232, 4697, 4419, 2739, 1029,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]) tensor([ 101, 2054, 2003, 1996, 2779, 6451, 3021, 1999, 8955, 1029,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for _, i in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "    print(_)\n",
    "    print(i.shape)\n",
    "    print(i[0][0], i[0][1], i[0][2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6644, -0.3830, -0.9211,  ..., -0.7755, -0.5754,  0.7168],\n",
       "        [-0.7301, -0.3435, -0.8384,  ..., -0.6896, -0.6478,  0.7646],\n",
       "        [-0.7458, -0.3820, -0.9208,  ..., -0.7530, -0.5866,  0.7146]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert(test_trip_toks[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.tensor(tokenizer.batch_encode_plus(data_batch, max_length=20, pad_to_max_length=True)['input_ids']))\n",
    "torch.tensor(tokenizer.batch_encode_plus(data_batch, max_length=20, pad_to_max_length=True)['input_ids']).shape\n",
    "pp = torch.tensor(tokenizer.batch_encode_plus(data_batch, max_length=20, pad_to_max_length=True)['input_ids'])\n",
    "op = bert(pp)\n",
    "len(op), len(op[0]), len(op[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "torch.Size([3, 20, 768])\n",
      "Last layer:\n",
      "tensor([[-7.6433e-02, -8.9489e-02, -1.3672e-01,  ..., -6.6198e-02,\n",
      "          5.6868e-01, -1.7539e-02],\n",
      "        [-3.7741e-01,  2.4381e-04,  2.9177e-02,  ..., -2.3378e-01,\n",
      "          5.8122e-01, -1.1460e-01],\n",
      "        [-2.2106e-01, -1.2737e-02,  2.2621e-01,  ..., -4.2140e-01,\n",
      "          5.4900e-01,  2.6106e-01]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 12):\n",
    "    print(op[0][i].shape)\n",
    "\n",
    "\n",
    "print(\"Last layer:\")\n",
    "print(op[0][-1][:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0479e-01, -1.3670e-01,  2.8593e-01,  3.9472e-01, -2.8711e-01,\n",
      "        -9.5799e-03,  4.4399e-01,  1.9117e-01, -5.9215e-02, -1.5948e-01,\n",
      "         5.4828e-01, -7.1385e-02,  2.3403e-01,  8.3681e-02,  6.1395e-02,\n",
      "         2.3235e-01, -9.5476e-02,  4.1060e-01,  1.9296e-01, -8.3265e-03,\n",
      "         2.5403e-01,  3.4456e-01,  7.4730e-01, -8.3072e-02,  2.1567e-01,\n",
      "        -2.0264e-01,  2.2041e-01, -5.8181e-01, -3.8102e-01, -3.3458e-01,\n",
      "        -2.3308e-01,  4.7912e-01, -1.4395e-02, -3.1721e-01, -2.6404e-02,\n",
      "        -3.0581e-01, -1.6827e-01, -3.0518e-02,  5.3785e-01, -3.6537e-01,\n",
      "        -3.6258e-01, -3.0649e-02,  4.5609e-01,  9.6171e-02, -1.9731e-01,\n",
      "        -1.7379e-01, -3.9627e+00,  9.1790e-02, -2.7941e-01, -2.9545e-01,\n",
      "        -1.2409e-01,  6.4611e-02,  2.0612e-01, -6.6146e-03, -5.4270e-02,\n",
      "         6.2808e-01, -2.9875e-01, -1.2810e-01,  7.8158e-01,  1.8447e-01,\n",
      "         2.5692e-01,  2.5277e-01, -3.7966e-01,  2.1000e-01, -1.1052e-01,\n",
      "         4.0831e-01, -1.5077e-01,  1.3938e-01, -3.1046e-01,  7.1553e-01,\n",
      "         1.8149e-01,  5.4392e-01,  2.1139e-01,  2.2384e-01, -1.4734e-01,\n",
      "        -4.1491e-01, -1.6617e-01,  3.7370e-01, -8.8892e-02, -3.0707e-01,\n",
      "         1.1933e-01,  9.4780e-02, -6.1406e-02, -3.7745e-01,  3.7850e-01,\n",
      "         2.6601e-01,  4.9637e-01, -2.5663e-01,  4.9536e-02,  4.2115e-01,\n",
      "         2.2361e-01, -5.5069e-03,  5.6148e-01,  6.0288e-01,  3.8888e-01,\n",
      "         8.7693e-02,  2.6177e-01, -1.6707e-01,  3.0580e-02,  1.7926e-01,\n",
      "        -2.7870e-04,  3.9784e-01,  2.8567e-01, -4.2479e-01, -1.5963e-01,\n",
      "        -2.1813e-01, -6.0310e-01,  3.7590e-02, -1.2769e-01, -7.9659e-01,\n",
      "        -7.5787e-02,  2.5937e-01, -2.1781e-01,  1.6061e-01,  3.2868e-01,\n",
      "         7.2145e-01,  5.1352e-01,  2.7553e-01,  1.2935e-01, -3.0244e-01,\n",
      "         2.9887e-01,  5.0754e-01,  3.0261e-01, -6.4765e-01,  6.3287e-02,\n",
      "         4.9129e-01, -6.0935e-02, -6.8511e-01,  8.0924e-02,  1.5252e-01,\n",
      "         3.4612e-01,  1.2360e-01, -2.3962e-01, -4.0316e-01, -6.4975e-02,\n",
      "        -1.9736e-01,  8.0765e-02,  2.5127e-01, -3.2247e-02, -2.6697e-01,\n",
      "        -1.2512e+00, -2.3563e-01, -1.8594e+00, -3.4207e-01,  5.0553e-01,\n",
      "        -3.3000e-02, -1.8323e-01,  4.2305e-01, -2.9546e-01, -3.7097e-02,\n",
      "         2.0066e-01,  3.7612e-01, -3.3522e-01, -2.5195e-01, -2.2996e-01,\n",
      "        -2.6970e-01, -1.4508e-01, -3.9437e-01, -3.3937e-01,  8.1360e-01,\n",
      "        -1.3601e-01, -1.3770e-01, -3.1001e-01, -1.9534e-02, -4.9760e-01,\n",
      "        -4.4039e-01,  9.2478e-02, -1.8423e-01,  2.1486e-03,  7.4050e-02,\n",
      "        -1.8389e-01, -3.2427e-01,  3.6326e-01, -4.3439e-01, -1.1176e-01,\n",
      "        -4.6285e-02,  1.9703e-01,  5.1706e-01,  2.3319e-01,  4.8155e-01,\n",
      "         8.3034e-02,  3.3396e-02, -8.3951e-02, -1.5223e-01,  8.2638e-02,\n",
      "         1.7925e-01, -1.6682e-01,  3.6896e-01, -5.8776e-02,  9.2075e-02,\n",
      "        -1.1098e+00, -4.2139e-01,  4.3034e-01,  3.7142e-01,  7.0533e-01,\n",
      "         9.1040e-02, -2.9673e-01, -7.4550e-02, -3.1608e-02,  1.2439e-02,\n",
      "         7.8439e-02,  4.3487e-01, -9.1677e-02,  4.5795e-01, -2.4891e-01,\n",
      "         2.1303e+00,  2.2923e-01,  2.7931e-01,  2.1263e-02, -5.1218e-01,\n",
      "        -4.0810e-01, -3.9810e-01, -7.7960e-02, -1.7346e-01, -9.5380e-02,\n",
      "         7.4990e-02, -1.8959e-01, -3.9586e-01, -2.9380e-02, -1.1670e-01,\n",
      "        -2.4138e-01, -6.0242e-02, -1.6290e-01,  4.1602e-01,  1.1531e-01,\n",
      "        -4.3969e-01,  1.5819e-01, -2.1186e-01,  1.0828e-01, -1.3758e+00,\n",
      "         2.6473e-02, -8.0677e-01, -2.3280e-01,  1.5375e-01,  1.6580e-02,\n",
      "         2.0700e-01,  4.4311e-01, -3.8554e-01,  1.2015e-01,  1.9461e-01,\n",
      "        -3.4989e-01,  5.1478e-01, -2.3582e-02,  1.5328e-03, -1.8415e-01,\n",
      "         1.4378e-01,  4.6222e-02, -5.6205e-01, -2.0934e-01, -3.0629e-02,\n",
      "         5.0303e-02,  8.5578e-02,  8.4842e-02,  4.6425e-02,  3.1301e-01,\n",
      "        -5.1715e-02,  6.3462e-03,  3.7099e-01, -4.9043e-01, -4.5464e-01,\n",
      "        -4.6134e-01,  1.0329e-01, -1.5206e-01,  1.7248e-01, -5.2189e-01,\n",
      "        -1.1189e-01, -1.0742e-02, -1.3044e-01,  4.1841e-01,  9.5333e-02,\n",
      "        -1.0209e-01, -3.2970e-01, -4.2405e-01, -1.3236e+00, -2.3854e-01,\n",
      "        -3.2353e-01,  1.0471e+00, -5.0033e-03, -8.2631e-01, -2.1108e-01,\n",
      "         1.3332e-01, -5.3396e-02, -2.1951e-01, -6.0973e-02, -8.7402e-02,\n",
      "        -2.7708e-01,  4.5846e-01, -4.8657e-01,  7.7045e-01,  1.1679e-01,\n",
      "        -2.0352e-01, -2.4697e-02, -2.4613e-01,  1.1761e-01,  4.8597e-01,\n",
      "        -5.3819e-01,  1.5545e-02, -1.0685e-01,  2.4420e-01,  2.9337e-01,\n",
      "        -6.7042e-02,  1.4285e-01, -1.7813e-01,  3.9596e-01, -4.6967e-01,\n",
      "         2.2852e-02, -2.9323e-01,  4.1365e-01, -5.2193e+00,  3.3314e-01,\n",
      "        -2.8178e-01, -1.7480e-01,  1.0341e-01,  1.3191e-01,  5.2465e-01,\n",
      "         1.0622e-01, -3.5216e-01,  1.5183e-01,  1.6133e-01,  2.3267e-01,\n",
      "        -2.3597e-01,  1.7630e-01, -2.2779e-01, -3.8385e-02,  1.0713e+00,\n",
      "        -3.1904e-02,  1.2731e-01,  4.1111e-01, -6.3114e-02, -2.5752e-02,\n",
      "         5.3847e-01,  3.5971e-01,  4.8410e-01, -7.6151e-02, -2.0849e-01,\n",
      "        -3.4311e-01, -1.0400e-01,  3.9874e-01, -4.7086e-02,  9.9483e-02,\n",
      "         1.5771e-01, -3.6667e-01, -1.6418e-01,  2.9543e-02, -6.0481e-02,\n",
      "        -3.4116e-01,  2.3021e-01,  3.9324e-01,  1.4460e-01, -1.7534e-01,\n",
      "         7.2179e-02,  1.5718e-01,  7.7487e-03, -5.9539e-01,  1.8345e-01,\n",
      "         9.4198e-01,  2.5666e-01,  4.2404e-01,  3.0597e-01, -2.0341e-01,\n",
      "         8.0331e-01, -2.7076e-01, -8.4677e-02, -4.9761e-02,  4.1636e-01,\n",
      "        -1.0660e-01, -1.3193e-01, -5.3554e-02,  8.1766e-01,  1.2746e-02,\n",
      "        -3.8706e-02, -3.3315e-01, -1.2591e-02, -6.8175e-01,  1.0148e-02,\n",
      "        -2.1822e-01, -8.1053e-01,  9.3540e-02, -6.1477e-01,  4.1457e-01,\n",
      "         1.7381e-01, -1.2476e+00,  1.8974e-01, -1.4907e-01, -3.1833e-01,\n",
      "         1.4753e-01, -1.3216e-01,  2.9167e-01, -5.4959e-01,  4.5924e-02,\n",
      "         8.3879e-02,  9.6073e-01, -7.3406e-01,  1.4134e-01, -1.8760e-01,\n",
      "         7.6259e-01, -6.5621e-01,  3.7269e-01,  2.4047e-02,  3.2207e-02,\n",
      "         3.6690e-01,  1.0187e-01,  4.6404e-01,  9.0982e-01,  5.0910e-01,\n",
      "        -2.0488e-01,  5.1483e-01, -6.8872e-03,  4.7235e-01,  5.9516e-02,\n",
      "        -9.6467e-02,  1.6156e-01, -5.1063e-03,  1.6248e-01, -3.5513e-01,\n",
      "         2.1774e-01,  9.5757e-01, -2.2407e-01, -1.7682e-01,  3.0055e-02,\n",
      "        -4.5219e-01,  1.7460e-01,  5.6068e-01, -3.4289e-01, -5.6990e-02,\n",
      "         3.9501e-01,  5.7646e-01,  1.9472e-01,  1.4712e-01,  1.6140e-01,\n",
      "        -3.6931e-01, -3.4156e-01, -3.5221e-01,  2.6812e-01,  1.1412e-01,\n",
      "         2.3251e-01, -6.2388e-02, -3.2459e-01,  1.2486e-01, -4.8100e-01,\n",
      "        -9.1504e-01, -5.5558e-01,  9.9082e-02,  9.7218e-02,  2.4125e-01,\n",
      "        -1.5060e-01,  1.7099e-01, -3.4634e-01,  6.0416e-01, -5.9128e-02,\n",
      "        -1.9461e-01,  3.6772e-01, -1.8639e-01, -6.6055e-02,  2.9262e-03,\n",
      "        -2.2401e-01, -3.3390e-01,  3.4419e-01,  2.6437e-01, -1.6182e-01,\n",
      "         8.5592e-02, -8.3035e-01,  1.9626e-01,  4.0099e-01,  1.8756e-02,\n",
      "        -3.0228e-01, -6.7527e-01, -2.9520e-01,  8.4570e-01, -1.2693e-01,\n",
      "        -1.0990e+00, -2.9256e-01,  5.6446e-01,  1.7051e-01,  3.7417e-01,\n",
      "        -9.8257e-02,  2.8993e-02,  2.0074e-01, -1.7417e-01,  1.6873e-01,\n",
      "        -4.6522e-01, -4.6052e-02,  6.0035e-02,  4.1955e-01,  3.7793e-01,\n",
      "        -8.4817e-02,  1.8092e-01, -3.4730e-01, -1.3500e-01, -5.9711e-01,\n",
      "         3.3495e-01, -1.3616e-01,  4.2794e-01, -9.5880e-02, -8.4586e-02,\n",
      "        -3.9418e-01, -3.5782e-01,  7.5074e-02, -2.8915e-01,  2.6768e-01,\n",
      "         3.6013e-03, -9.2367e-01, -9.6714e-02, -3.2645e-01,  3.9678e-01,\n",
      "         5.3819e-01,  2.0779e-01, -8.2290e-02, -2.1722e-01,  2.9918e-01,\n",
      "        -7.0449e-01,  3.4608e-02,  8.5825e-01, -4.2082e-02,  3.7959e-02,\n",
      "        -4.3750e-02, -5.4413e-02,  6.0093e-02,  1.7566e-02, -2.1790e-01,\n",
      "         2.4023e-02, -1.1918e-01,  5.1605e-02, -2.9053e-01, -5.5177e-01,\n",
      "        -8.1915e-02, -4.4934e-01, -1.3901e-01, -1.7603e-01,  6.5168e-02,\n",
      "         5.4724e-01, -2.9007e-01, -1.2445e-01, -1.9651e-01, -3.5701e-01,\n",
      "        -3.6118e-01,  9.3494e-02, -1.7727e-01, -2.3607e-01,  1.7603e-01,\n",
      "         1.5437e-01,  3.5571e-01, -9.8408e-01, -3.1087e-01, -1.5081e-01,\n",
      "         2.3259e-01, -7.0278e-02,  5.2349e-01,  3.2953e-01, -5.4476e-01,\n",
      "         5.2830e-01, -3.5644e-01,  2.6512e-01,  8.6147e-01, -2.2641e-01,\n",
      "        -2.7700e-01,  9.9936e-02, -1.8594e-01,  5.9669e-01,  8.1759e-02,\n",
      "        -2.8355e-01, -4.4726e-01,  3.7048e-01, -1.0641e-01,  3.8466e-02,\n",
      "        -1.4171e-01, -1.6777e-01, -2.0223e-01, -3.9348e-01,  2.9154e-01,\n",
      "         8.2253e-02,  4.8200e-01,  1.6794e-01, -1.5307e-01, -2.1231e-01,\n",
      "         3.4406e-01,  7.0171e-01, -3.7755e-01, -7.9894e-01, -1.1551e-01,\n",
      "        -5.3448e-02,  3.2826e-01,  1.8293e-01,  1.0415e-01, -1.2171e-01,\n",
      "         1.0660e-01,  2.3564e-01, -7.6438e-01,  1.0567e+00,  1.0061e-01,\n",
      "         4.5224e-01,  5.2025e-01,  3.8776e-01,  1.3480e-01, -4.4131e-01,\n",
      "         6.6521e-02,  2.1947e-01,  4.6799e-01, -2.7892e-01,  3.2122e-01,\n",
      "        -2.9051e-01, -3.0310e-01,  1.3922e-01,  7.1302e-01,  9.4464e-02,\n",
      "        -2.4141e-01, -9.2732e-01, -1.8193e-01, -2.0924e-01,  4.4048e-01,\n",
      "         9.2085e-01, -2.7503e-01, -3.8870e-02,  4.5056e-01,  3.8639e-02,\n",
      "        -2.0329e-02, -1.0059e-01,  9.5991e-02,  1.2839e-01,  3.4084e-01,\n",
      "         4.8685e-02,  2.5696e-01,  1.2161e-01,  8.9172e-02, -7.0159e-01,\n",
      "        -2.6782e-01, -3.8980e-02,  5.8786e-01,  2.8894e-01,  4.6322e-02,\n",
      "         8.9827e-01,  4.2363e-02, -2.8219e-01,  4.1470e-01,  1.2447e-01,\n",
      "        -7.4528e-01,  7.6773e-02,  8.8722e-01,  1.5469e-01,  7.7407e-02,\n",
      "        -4.5873e-01,  1.1268e-01,  1.7960e-01, -1.3417e-01, -2.4419e-01,\n",
      "        -8.0981e-01, -3.3274e-01,  4.8639e-01, -5.1478e-01,  1.1080e-01,\n",
      "         6.8054e-01, -5.4165e-01, -6.6555e-01,  7.6954e-02,  3.0965e-01,\n",
      "         1.3513e-01,  8.5624e-02, -4.1747e-01,  2.5568e-01,  5.6033e-01,\n",
      "         1.5547e-01,  6.8717e-01,  1.1588e-01,  6.8117e-01,  3.6532e-01,\n",
      "        -4.6639e-01, -4.5243e-01, -9.9545e-01, -3.0930e-01, -4.5855e-03,\n",
      "         1.8530e-01, -3.0649e-01, -3.8251e-02, -7.1614e-03,  1.9554e-02,\n",
      "         2.6687e-01, -2.0853e-01,  1.9463e-01,  4.4483e-01,  4.1836e-01,\n",
      "        -1.3850e-01, -1.5137e-01,  8.9372e-02,  1.9427e-01,  2.5695e-02,\n",
      "        -1.9803e-01, -1.4935e-01, -2.1704e-01, -4.0893e-01, -6.6915e-01,\n",
      "         4.9491e-02, -2.7153e-01,  2.1609e-01,  4.2467e-01, -2.8571e-02,\n",
      "         6.7507e-02,  8.8171e-02, -2.0177e-01,  1.3584e-01, -1.6325e-01,\n",
      "         1.6477e-01,  3.9130e-01, -2.0649e-02,  2.4537e-01, -1.5270e-01,\n",
      "         2.0701e-01,  5.5952e-01,  9.6421e-02,  5.7087e-01,  2.8001e-03,\n",
      "         5.0625e-01, -8.8169e-03, -3.9714e-01,  3.8996e-01, -7.4224e-02,\n",
      "         5.7758e-01, -4.4714e-01, -3.5344e-01,  6.5847e-02, -2.9017e-01,\n",
      "         4.5349e-01,  2.2196e-01, -1.6769e-01, -1.2245e-01, -5.9924e-02,\n",
      "         1.4353e-01,  1.4771e-01, -8.3978e-01, -3.0977e-01, -5.1688e-01,\n",
      "         7.3598e-02,  4.8553e-01, -1.1873e-01,  1.9661e-01,  2.0588e-01,\n",
      "         8.5638e-02, -8.7324e-01, -4.6845e-02, -3.9978e-01,  4.0531e-01,\n",
      "         2.3948e-01,  1.6871e-01, -2.7988e-01, -8.3802e-02,  8.3647e-01,\n",
      "        -9.9525e-02,  1.6758e-01, -5.1296e-02,  4.4437e-01,  3.3486e-01,\n",
      "         2.4894e-01,  5.8957e-01, -4.0678e+00, -2.7200e-01,  3.6725e-01,\n",
      "        -1.1419e-01, -2.0893e-01, -1.5274e-01, -4.4549e-01, -3.5915e-01,\n",
      "         1.1365e-01, -5.2403e-02, -5.9495e-02, -4.7315e-02, -3.0438e-01,\n",
      "         1.3238e-01,  8.2316e-01,  1.0652e-01], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(op[0][-1][:,0,:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4680e-01, -4.5984e-01,  6.1936e-02,  3.3654e-01, -4.3310e-01,\n",
      "        -3.1909e-02,  6.8949e-01,  2.8380e-01, -2.2587e-01, -1.1740e-01,\n",
      "         4.5956e-01, -5.1627e-01,  3.7880e-02,  5.9976e-01,  7.3889e-02,\n",
      "         1.5098e-01, -3.9343e-01,  6.3144e-01, -8.1088e-03,  4.7656e-02,\n",
      "         3.2977e-01,  1.2260e-01,  6.4057e-01, -1.7358e-01, -1.1333e-01,\n",
      "        -1.1013e-01,  3.1231e-01, -4.3369e-01, -2.8091e-01, -2.9654e-01,\n",
      "        -5.8493e-01,  1.4303e-01, -2.4939e-01, -2.5161e-01,  6.0594e-03,\n",
      "        -5.9773e-01, -4.3773e-01, -1.4739e-01,  4.8842e-01, -4.6687e-01,\n",
      "        -7.2992e-01, -3.9896e-01,  2.1405e-01, -2.8487e-01,  1.6911e-02,\n",
      "        -4.6969e-01, -3.9771e+00, -2.1120e-01, -3.4707e-01, -4.6502e-01,\n",
      "        -4.9656e-02,  2.0078e-02,  6.4202e-01,  2.1692e-01, -7.6416e-02,\n",
      "         6.8904e-01, -1.3983e-01, -2.0804e-01,  8.4225e-01,  1.2888e-01,\n",
      "         1.2685e-01,  4.2034e-01, -3.5567e-01,  6.0724e-02,  1.0310e-01,\n",
      "         7.3485e-01, -2.9214e-01,  5.2459e-01,  3.0427e-02,  6.5090e-01,\n",
      "        -7.0991e-02,  6.8628e-01,  5.8440e-01,  2.7247e-01, -1.5792e-01,\n",
      "        -2.8926e-01,  5.8143e-02,  3.5670e-01, -2.1754e-01, -1.6450e-01,\n",
      "        -2.8552e-01, -7.3745e-02, -1.3577e-02, -2.3482e-01,  2.8273e-01,\n",
      "         5.8526e-01, -2.5685e-02, -4.2261e-01, -9.7321e-02,  8.0835e-01,\n",
      "        -1.6992e-01,  1.7650e-01,  5.6627e-01,  6.7972e-01,  2.4399e-01,\n",
      "        -2.5605e-01,  1.4203e-01, -2.3258e-01,  4.9626e-02,  3.5557e-01,\n",
      "         1.3257e-02,  8.2389e-01,  5.2930e-01, -5.5039e-01, -7.4337e-02,\n",
      "        -4.2253e-01, -6.5270e-01, -1.2314e-01, -9.0220e-02, -1.1602e+00,\n",
      "         1.1090e-01,  2.7554e-01, -2.7835e-02, -7.3381e-02,  6.2906e-01,\n",
      "         6.1524e-01,  8.9026e-01,  1.2892e-01,  3.1993e-01, -4.3632e-01,\n",
      "         2.5124e-01,  5.4452e-01,  1.7903e-01, -6.6523e-01,  3.3591e-02,\n",
      "         7.1915e-01, -2.4457e-01, -9.5605e-01,  5.1476e-01,  1.6238e-01,\n",
      "         4.2059e-01,  4.6000e-01, -6.0529e-02, -2.9716e-01, -4.0935e-01,\n",
      "        -2.8924e-01,  6.2045e-02,  7.0886e-01,  2.1673e-01, -3.3665e-01,\n",
      "        -1.4467e+00, -5.5844e-01, -1.5909e+00, -3.7108e-01,  9.2607e-01,\n",
      "         3.8307e-02, -2.2427e-01,  6.9686e-02,  1.1523e-01,  2.9604e-01,\n",
      "         1.3059e-01,  8.7407e-02, -2.0445e-01, -9.6441e-02, -5.1568e-01,\n",
      "        -4.2726e-01, -4.3856e-02, -2.4937e-01, -3.7442e-01,  7.9720e-01,\n",
      "        -8.9435e-02, -3.6695e-01, -3.3941e-01,  2.1221e-01, -4.8020e-02,\n",
      "        -2.4891e-02,  6.5667e-01,  5.1046e-01, -1.4512e-01,  1.5954e-01,\n",
      "        -4.0725e-01,  2.0762e-01,  3.4997e-01, -4.3067e-01,  5.3484e-02,\n",
      "         1.4386e-01,  4.1727e-01,  9.3940e-01,  5.8630e-02,  1.2288e-01,\n",
      "        -8.6591e-01,  1.0499e-01,  5.1511e-02, -1.5480e-01, -1.5195e-01,\n",
      "         2.7840e-01,  4.8381e-01,  4.3310e-01, -1.2411e-01,  3.0083e-01,\n",
      "        -4.9434e-01, -5.3155e-01,  4.6956e-01,  5.1539e-01,  7.5507e-01,\n",
      "         1.2501e-01, -1.2516e-01,  2.4926e-01, -3.0457e-01,  2.4902e-01,\n",
      "        -5.1763e-02,  5.3029e-02,  1.5071e-01,  6.2261e-01,  1.7002e-01,\n",
      "         2.2812e+00,  1.1108e-01,  7.7293e-01,  1.9000e-01, -1.3869e-01,\n",
      "        -3.9808e-01, -5.8720e-01, -6.9033e-02, -7.7419e-02, -3.9436e-01,\n",
      "        -1.4401e-01,  2.9275e-02, -1.6337e-01, -7.8053e-02,  6.1475e-04,\n",
      "         1.0494e-01, -7.8623e-02, -5.7641e-01,  2.4729e-01,  5.6658e-02,\n",
      "        -3.0727e-01, -3.1310e-01, -2.1765e-01,  2.2242e-01, -1.7100e+00,\n",
      "         1.8763e-01, -1.3824e-01, -2.0781e-01,  1.2611e-01, -2.0982e-01,\n",
      "        -8.6992e-02,  3.1147e-01, -4.5064e-01, -1.5736e-01, -2.6197e-02,\n",
      "        -9.4887e-02,  2.7832e-01,  8.6674e-02,  9.7379e-02, -1.1302e-01,\n",
      "         3.7624e-01,  4.1115e-01, -3.2429e-01, -2.6105e-01, -8.5618e-02,\n",
      "         1.8637e-01,  2.9598e-01,  3.1959e-01, -2.2502e-01,  2.2010e-01,\n",
      "        -6.2336e-02, -2.0162e-01,  2.8177e-01, -3.6396e-01, -5.0397e-01,\n",
      "        -5.1367e-01, -3.0167e-01, -2.2619e-01,  5.3030e-01, -4.3165e-01,\n",
      "        -4.6731e-01,  1.7807e-01, -1.1885e-01,  1.9689e-01, -5.4287e-01,\n",
      "        -3.8038e-02, -7.4581e-01, -2.7755e-01, -2.1376e+00,  2.8776e-01,\n",
      "        -4.4643e-01,  4.0603e-01, -2.8301e-01, -9.4245e-01, -1.0096e-01,\n",
      "         1.8318e-02,  3.5534e-01, -6.5468e-01,  1.7789e-01, -2.8132e-01,\n",
      "        -2.7647e-01,  5.7004e-01, -5.6594e-01,  4.4530e-01,  1.0269e-01,\n",
      "        -3.4097e-01,  2.4433e-01, -3.5992e-01,  1.4636e-01,  1.8772e-01,\n",
      "        -4.0128e-01,  7.3040e-02, -1.5663e-01,  5.1190e-01,  1.4043e-01,\n",
      "         1.4790e-02,  1.2345e-01, -5.1374e-01,  5.1729e-01, -6.0972e-01,\n",
      "         2.9597e-01, -3.7464e-01,  4.3222e-01, -3.8750e+00,  2.3476e-01,\n",
      "        -4.7071e-01, -3.6131e-02, -2.9464e-02,  1.7848e-02,  7.4392e-01,\n",
      "        -5.2354e-02, -3.5828e-01,  4.5749e-01,  1.4225e-01,  2.1741e-01,\n",
      "        -2.3922e-01,  3.8142e-01, -5.9559e-02, -1.5721e-01,  1.1401e+00,\n",
      "        -9.0549e-02,  3.5708e-01,  4.1107e-01, -8.9008e-02, -1.6867e-01,\n",
      "         3.5358e-01,  6.3467e-02,  4.8347e-01,  8.8399e-02, -2.6275e-01,\n",
      "        -5.2743e-01,  2.5743e-02,  7.4501e-01,  1.3350e-02, -3.1002e-01,\n",
      "        -8.3183e-03, -3.1949e-01, -2.2558e-01, -2.9116e-01, -2.0071e-01,\n",
      "        -2.1995e-01,  6.0566e-01,  4.7840e-01,  3.9293e-01, -2.9274e-01,\n",
      "        -8.7807e-02,  3.8927e-01,  2.0813e-01, -5.8206e-01,  1.7633e-01,\n",
      "         6.5516e-01,  4.0883e-02,  7.6037e-01, -6.3619e-02,  3.5353e-01,\n",
      "         1.1642e+00, -3.3252e-01,  1.5340e-01, -1.2261e-01,  4.5153e-01,\n",
      "        -2.7282e-01, -1.0319e-01,  2.5187e-01,  8.8451e-01,  2.5529e-01,\n",
      "        -7.5851e-02, -3.8065e-01,  2.6683e-02, -1.3162e+00, -3.3885e-01,\n",
      "        -2.9765e-01, -4.2814e-01,  1.2672e-01, -7.0468e-01,  1.8765e-01,\n",
      "        -7.8565e-02, -1.0323e+00,  6.0644e-02,  2.1062e-01, -2.5052e-01,\n",
      "         1.1935e-01, -5.3301e-01,  3.8936e-01, -7.5864e-01, -1.6048e-01,\n",
      "        -3.0601e-01,  8.3679e-01, -6.2933e-01,  2.4299e-01, -1.0958e-01,\n",
      "         7.1672e-01, -1.0567e+00,  4.3928e-01,  4.9558e-03,  6.8408e-02,\n",
      "         5.7032e-01, -1.3852e-02, -3.7954e-03,  6.3704e-01,  1.6780e-01,\n",
      "        -5.6736e-01,  4.5535e-01,  4.7002e-02,  5.8277e-02, -2.2621e-02,\n",
      "        -1.2513e-01,  4.5554e-03,  1.8428e-01, -2.3734e-01, -2.4599e-01,\n",
      "        -4.3186e-02,  1.0722e+00, -1.1111e-01, -4.0462e-01, -5.7700e-02,\n",
      "        -6.1183e-01,  8.2443e-02,  6.4660e-01,  1.4951e-01,  1.3674e-01,\n",
      "         6.8347e-01,  7.0602e-01,  6.3943e-01,  6.2651e-02,  1.6752e-02,\n",
      "        -4.6970e-01, -9.2301e-01, -2.7091e-01,  2.0513e-01, -9.1356e-02,\n",
      "         2.3685e-01, -1.6931e-01, -1.9845e-01,  1.7533e-01,  1.5137e-01,\n",
      "        -1.1924e+00, -2.6083e-01,  1.7996e-01, -2.2827e-01, -2.8559e-01,\n",
      "        -6.3304e-01,  2.9719e-01, -2.9367e-01,  5.7511e-01, -3.2725e-01,\n",
      "        -3.0433e-01,  3.9648e-01, -6.1256e-02,  1.3376e-01,  3.9677e-01,\n",
      "        -3.5950e-01,  8.9775e-02,  5.5405e-01,  2.2962e-01, -1.8390e-01,\n",
      "         9.5399e-02, -8.1269e-01, -1.8166e-01,  3.6325e-01,  1.0927e-01,\n",
      "        -4.5892e-01, -3.8796e-01, -2.7894e-01,  8.8882e-01,  1.5533e-03,\n",
      "        -1.9862e+00,  7.3860e-03,  9.3705e-01,  1.6015e-01,  2.5058e-01,\n",
      "        -3.3355e-03, -1.2153e-01,  2.0493e-01, -3.5411e-01, -7.4834e-02,\n",
      "        -6.8213e-01, -1.9548e-01,  1.1262e-01,  3.1032e-02,  3.0909e-01,\n",
      "        -2.3777e-01,  1.6400e-01, -1.8709e-01, -2.4053e-01, -4.1948e-01,\n",
      "         1.0631e-01,  3.2347e-01,  5.3067e-01,  3.5568e-01, -1.6430e-01,\n",
      "        -1.5939e-01, -8.4763e-02,  1.8105e-01, -2.4825e-01,  5.1898e-01,\n",
      "        -9.9825e-02, -1.2127e+00, -5.3644e-01, -3.7662e-01,  4.7810e-01,\n",
      "         3.8013e-01,  2.2768e-01, -9.0365e-02, -6.0573e-02,  4.3104e-01,\n",
      "        -3.1942e-01,  2.6367e-01,  1.2986e+00,  2.7110e-01,  1.2138e-01,\n",
      "         7.5694e-03, -3.5393e-01,  2.7392e-01,  2.1598e-02, -5.5615e-01,\n",
      "        -1.3542e-01, -2.2878e-01,  2.8830e-01, -6.0510e-01, -4.5044e-01,\n",
      "        -7.4165e-02, -1.2178e-01, -1.4606e-01, -1.2978e-01, -6.7207e-02,\n",
      "         4.6149e-01, -7.2067e-01, -1.0914e-01, -4.7243e-01, -4.4732e-01,\n",
      "        -5.9332e-01, -9.1386e-02, -6.2424e-01, -2.6193e-01,  1.5085e-01,\n",
      "         6.0827e-01,  4.9800e-01, -1.0793e+00, -3.8340e-02, -2.9705e-01,\n",
      "        -3.4247e-02,  2.1177e-01,  1.1917e+00,  5.8805e-01, -5.7964e-01,\n",
      "         3.0775e-01, -5.5439e-01,  3.4029e-01,  1.0394e+00, -1.1330e-01,\n",
      "        -3.0519e-02, -3.1248e-02,  9.8852e-02,  2.2986e-01, -1.2529e-01,\n",
      "        -7.2496e-01, -5.3596e-01,  6.5806e-01,  6.7003e-03,  7.1862e-02,\n",
      "         1.4600e-01, -4.6798e-01,  4.9420e-02, -5.1446e-01, -3.2737e-03,\n",
      "         2.3974e-01,  4.5978e-01,  5.6010e-01,  2.0842e-02, -7.9641e-02,\n",
      "         1.1164e+00,  3.8382e-01, -2.8088e-01, -1.1880e+00, -2.2488e-01,\n",
      "         3.5702e-01,  8.2362e-02, -1.7301e-01, -3.4780e-02,  3.9687e-01,\n",
      "        -3.3131e-02,  3.6607e-01, -8.0214e-01,  1.6581e+00,  5.0500e-01,\n",
      "         3.5745e-01,  5.1711e-01,  3.7374e-01,  2.8557e-01, -3.8779e-01,\n",
      "        -2.8966e-01,  8.2583e-04,  8.1705e-01, -8.3070e-01,  2.8594e-01,\n",
      "        -4.5962e-01, -2.6737e-01,  5.6289e-01,  9.7462e-01,  3.1986e-01,\n",
      "        -5.2012e-01, -1.1126e+00, -1.2416e-01, -1.0157e-01,  6.4377e-01,\n",
      "         1.0124e+00, -3.5916e-01, -2.0003e-01,  1.4573e-01, -1.2434e-01,\n",
      "         8.8781e-02, -2.7317e-01,  1.5356e-01,  1.7080e-01,  3.2502e-01,\n",
      "        -4.2875e-02,  4.4217e-01, -8.6314e-02,  1.3872e-01, -6.1357e-01,\n",
      "        -3.3303e-01, -3.4637e-01,  6.3643e-01,  2.7857e-01,  4.1089e-02,\n",
      "         8.8576e-01, -2.4697e-01, -1.0037e-01,  8.7655e-01,  3.7740e-02,\n",
      "        -5.0622e-01, -1.0786e-01,  7.3001e-01, -1.9677e-02, -1.6165e-01,\n",
      "        -5.4912e-01,  3.1323e-01, -1.1299e-01, -2.8966e-01, -3.4325e-01,\n",
      "        -4.7092e-01, -4.9430e-01,  2.7759e-01, -6.4348e-01,  2.9840e-01,\n",
      "         1.8089e-01, -5.4595e-01, -8.8870e-01, -5.9818e-03,  2.9822e-01,\n",
      "         1.6007e-01,  3.1091e-02, -2.9775e-01,  2.6286e-01,  3.6449e-01,\n",
      "         4.6407e-01,  2.7125e-01,  3.7937e-01,  6.7563e-01,  3.2678e-01,\n",
      "        -4.4161e-01, -3.0604e-01, -1.5865e+00, -2.2833e-01, -3.7340e-02,\n",
      "         5.8921e-01, -3.6212e-01,  3.8894e-01, -1.5475e-01, -1.3076e-01,\n",
      "         6.8835e-01, -2.2090e-01,  1.5803e-01,  7.8378e-01,  5.1706e-01,\n",
      "        -4.9043e-01, -3.4814e-01,  2.2872e-01,  5.6106e-01,  7.6284e-02,\n",
      "        -6.2434e-02, -2.2850e-01, -1.3385e-01, -2.8168e-01, -7.3157e-01,\n",
      "        -2.3335e-02, -6.8501e-01,  1.8005e-01,  8.3550e-01, -3.3922e-01,\n",
      "         1.5251e-03,  2.7119e-01,  1.1251e-01,  4.9558e-01, -1.4022e-01,\n",
      "         2.4691e-01,  1.1219e-01, -2.9895e-01,  2.7244e-01,  7.8751e-02,\n",
      "        -1.4150e-01,  3.7396e-01,  4.2679e-02,  9.7033e-01,  7.3420e-02,\n",
      "         7.6796e-01, -9.0318e-02, -4.4128e-01,  1.1730e-01, -2.6515e-02,\n",
      "         9.6618e-01, -4.5507e-01, -9.0883e-02,  1.6287e-03, -1.2209e-01,\n",
      "         6.4299e-01,  6.1021e-02,  1.5146e-02, -6.1453e-01,  1.9791e-02,\n",
      "         9.8938e-02, -4.0449e-02, -6.7690e-01, -1.3442e-01, -4.2303e-01,\n",
      "         2.2788e-01,  7.4902e-01, -3.4835e-02,  1.0474e-01,  3.2244e-01,\n",
      "        -2.8372e-01, -1.0197e+00, -6.1957e-02, -8.0553e-02,  7.3307e-01,\n",
      "         4.0355e-01,  2.0637e-01, -5.5234e-02, -3.6853e-01,  1.1314e+00,\n",
      "         1.4640e-01,  2.7280e-01, -3.4811e-01,  5.5591e-01,  7.9303e-01,\n",
      "         1.0283e+00,  5.9323e-01, -5.1263e+00, -3.8754e-01, -8.2827e-03,\n",
      "        -2.7482e-01, -1.8238e-01, -4.9085e-01, -3.9044e-01, -4.9114e-01,\n",
      "        -1.4915e-01, -1.5285e-01,  1.2762e-01, -4.0096e-01, -3.2641e-01,\n",
      "        -5.0754e-02,  8.6107e-01,  1.0748e-01], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(op[0][-1][:,0,:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.0789e-01, -6.8875e-02,  3.6261e-01,  2.0112e-01, -1.5135e-01,\n",
      "         2.8060e-02,  8.3402e-01,  1.0176e-02, -1.1804e-01,  5.2988e-02,\n",
      "         1.7072e-01, -5.0285e-01,  1.6522e-02,  3.3955e-01,  6.9982e-02,\n",
      "         1.1600e-01, -1.1538e-01,  6.1831e-01,  3.2471e-01, -1.5858e-02,\n",
      "         1.4249e-01,  4.4013e-02,  5.2495e-01,  2.6497e-02, -2.9817e-01,\n",
      "        -2.6367e-01,  3.4122e-02, -3.6504e-01,  2.9245e-01,  1.8539e-01,\n",
      "        -4.0250e-01,  4.9998e-01,  2.1738e-01,  6.1250e-02,  4.8249e-01,\n",
      "        -9.2055e-02, -5.2978e-02, -1.5313e-01,  7.0847e-01, -2.6938e-01,\n",
      "         9.9794e-02, -2.6253e-01,  4.4361e-01,  2.2402e-02,  3.7130e-02,\n",
      "        -4.5729e-01, -3.6381e+00,  1.3415e-02, -2.7874e-01, -3.1738e-01,\n",
      "         7.8971e-03,  3.1639e-02,  6.3865e-01,  3.6483e-01, -5.1463e-01,\n",
      "         4.7512e-01, -2.1788e-01,  1.0854e-01,  8.3495e-01, -1.5587e-01,\n",
      "         1.7460e-01,  1.9191e-01, -1.7365e-01,  2.2614e-01, -3.8654e-01,\n",
      "         5.2357e-01, -3.5761e-01,  5.2230e-02, -9.2117e-02,  5.2119e-01,\n",
      "         2.0092e-01,  1.5690e-01,  1.6024e-01,  9.0510e-02,  3.3049e-02,\n",
      "        -3.7332e-01, -1.8478e-01,  5.0980e-01, -8.9901e-02, -2.1242e-01,\n",
      "         2.4339e-01, -9.4396e-02,  2.0537e-01, -8.0172e-01, -3.6399e-02,\n",
      "         4.5886e-01,  5.8132e-01, -3.2160e-01, -1.6534e-01,  5.6212e-01,\n",
      "         2.1747e-01,  1.0381e-01,  3.9290e-01,  2.4943e-01,  1.9439e-01,\n",
      "         1.0905e-01, -8.0598e-02,  1.2587e-01, -2.5400e-02,  2.5457e-01,\n",
      "        -1.3475e-01,  6.0859e-01, -1.0739e-01, -3.4080e-01, -2.6652e-02,\n",
      "        -4.2285e-01, -6.1560e-01,  1.4268e-01, -1.7719e-01, -9.2220e-01,\n",
      "         3.2239e-01,  2.1618e-01, -3.1728e-01, -1.9630e-02,  5.3500e-02,\n",
      "        -2.6307e-01,  5.4046e-01, -3.5194e-01,  1.0845e-01, -5.3257e-02,\n",
      "        -2.6148e-01,  2.7935e-01,  3.5490e-01, -3.4981e-01,  4.3098e-01,\n",
      "         2.0587e-01, -1.1662e-01, -9.2605e-01, -7.4828e-02,  5.2815e-01,\n",
      "         1.4514e-01,  2.3693e-01, -1.6351e-01, -1.2476e-01, -4.9835e-01,\n",
      "        -4.5730e-02,  3.9953e-01,  1.5171e-01,  1.1913e-01,  3.6430e-02,\n",
      "        -8.5681e-01, -3.4572e-01, -1.4906e+00,  4.1546e-02,  4.9402e-01,\n",
      "         2.4819e-01, -3.9465e-01,  2.3909e-01, -3.5666e-01, -2.5855e-01,\n",
      "        -1.5144e-01,  7.6225e-02, -4.7647e-01, -3.4526e-01, -2.0754e-01,\n",
      "        -4.2465e-02, -2.2959e-01, -1.2245e-01, -1.4061e-02,  8.5661e-01,\n",
      "        -3.7075e-02,  1.6910e-01, -6.7431e-02,  3.1204e-01, -1.4413e-01,\n",
      "         1.0346e-01,  3.3314e-01,  7.2645e-01, -2.9483e-02,  1.7323e-02,\n",
      "        -2.7723e-01, -1.4379e-01,  1.7502e-01, -1.4666e-01, -1.3781e-01,\n",
      "        -9.3704e-02,  4.9059e-01,  3.4567e-01,  1.9064e-01,  2.3183e-01,\n",
      "        -7.1729e-01, -2.7196e-02, -4.1277e-01, -9.5494e-03, -8.8189e-02,\n",
      "         2.8412e-01,  1.4044e-01,  3.9588e-01,  2.5644e-01,  2.6445e-01,\n",
      "        -9.4691e-01, -4.1636e-01,  6.4515e-01,  2.7342e-01,  4.5413e-01,\n",
      "         5.6394e-01, -2.5504e-01,  2.3168e-03,  4.0384e-01, -1.7506e-01,\n",
      "        -9.3769e-03,  5.4717e-01, -2.1326e-01,  5.1482e-01, -1.2781e-01,\n",
      "         2.8590e+00, -1.1147e-01,  1.4876e-01,  8.4363e-03, -3.9676e-02,\n",
      "        -3.7782e-01, -4.4127e-01, -4.7117e-01, -2.7011e-03, -4.7759e-02,\n",
      "        -3.7363e-01,  1.1714e-01, -3.5480e-02, -8.4396e-02,  2.3613e-02,\n",
      "        -2.9590e-01, -5.7776e-01,  8.6618e-02,  3.1714e-01,  3.2430e-03,\n",
      "        -1.9950e-01, -3.6810e-02,  2.3303e-01,  1.1050e-01, -1.2629e+00,\n",
      "         1.2194e-01, -7.0215e-01, -4.0053e-01,  3.3265e-01, -3.8871e-01,\n",
      "         3.3659e-01,  1.6296e-01, -2.3739e-01,  1.6607e-01,  1.9451e-01,\n",
      "        -5.8008e-02,  2.9522e-01,  1.5689e-01, -3.9934e-01, -2.7094e-01,\n",
      "        -2.2170e-01, -1.4923e-01, -7.5561e-01, -1.6065e-01, -2.1952e-01,\n",
      "        -3.1206e-02, -2.3786e-01,  1.1409e-01,  9.7297e-02,  4.9877e-02,\n",
      "        -1.4033e-01,  1.4621e-02,  7.2951e-02, -3.2633e-01, -4.0017e-01,\n",
      "        -3.1657e-01,  1.1089e-01,  2.6958e-02,  1.3001e-01, -7.4004e-02,\n",
      "        -2.8870e-01, -1.9618e-01,  7.6959e-03, -1.0625e-01, -1.0268e-01,\n",
      "        -1.7017e-01, -2.0086e-01, -1.2286e-01, -1.6074e+00,  4.9995e-01,\n",
      "         1.4775e-02,  9.4894e-01,  8.9188e-02, -2.9005e-01, -1.4122e-01,\n",
      "         7.4713e-03, -6.2408e-02, -2.8254e-01,  1.2715e-01, -1.8433e-01,\n",
      "         1.1384e-01,  2.2971e-01, -5.5868e-01,  3.5630e-01, -2.0548e-01,\n",
      "         2.1088e-01,  4.5287e-01,  2.2118e-01,  7.6275e-02,  3.4891e-01,\n",
      "        -5.5592e-01, -2.4502e-02, -2.2836e-01,  3.2764e-01,  8.4992e-02,\n",
      "        -1.4329e-01,  3.9800e-01, -2.9059e-01,  4.5666e-01, -1.6835e-01,\n",
      "        -3.7198e-04, -8.7984e-02,  4.2169e-01, -5.4223e+00, -7.2979e-02,\n",
      "        -1.9343e-01,  8.9130e-03, -4.0482e-02, -4.2097e-03,  8.5561e-01,\n",
      "         1.4618e-01, -2.0148e-01,  3.8391e-01, -1.9494e-01,  2.3759e-01,\n",
      "        -8.1835e-02,  6.7929e-02,  2.6577e-02, -6.5110e-02,  5.2779e-01,\n",
      "        -2.1739e-02,  3.1323e-01,  4.0173e-02, -3.7111e-01,  1.7840e-01,\n",
      "         3.0618e-01, -5.2338e-02,  2.1511e-01,  1.9990e-01, -1.5379e-01,\n",
      "        -9.7504e-02,  1.4006e-02,  9.6818e-03, -4.0192e-02, -5.5256e-01,\n",
      "        -7.7926e-02,  1.5425e-01, -3.1121e-01,  3.8517e-02,  2.3301e-02,\n",
      "        -3.2115e-01,  3.7426e-01,  4.2619e-02,  3.3919e-02,  4.0771e-02,\n",
      "         9.7309e-02,  1.2134e-01,  1.3154e-01, -3.7086e-01,  3.1093e-02,\n",
      "         2.7466e-01,  1.4831e-01,  5.4133e-01, -9.6319e-02,  4.2942e-02,\n",
      "         5.5379e-01, -2.5911e-01, -5.8299e-01, -4.7795e-02,  3.7140e-01,\n",
      "         5.7284e-02,  4.2103e-02, -3.1673e-01,  7.9594e-01,  1.6400e-01,\n",
      "        -3.0903e-01, -2.7789e-01,  3.5655e-01, -5.1213e-01,  8.1531e-02,\n",
      "        -4.1437e-01, -6.1873e-01,  2.5619e-01, -3.6102e-01, -4.6964e-02,\n",
      "         1.4109e-01, -1.2440e+00,  2.6873e-01, -1.2107e-01, -1.8105e-01,\n",
      "         1.5764e-01,  1.0261e-01,  1.2795e-01, -4.3208e-01, -8.5187e-03,\n",
      "         2.9323e-01,  9.0895e-01, -4.3362e-01,  4.2210e-01,  9.3433e-02,\n",
      "         1.3705e-01, -4.8347e-01,  7.7972e-01, -3.7572e-02, -2.9187e-01,\n",
      "         2.5351e-01,  3.8728e-01, -7.4628e-02,  7.2529e-01,  4.6728e-01,\n",
      "        -1.6189e-01,  4.1103e-01, -3.2606e-01,  6.0416e-01, -5.0466e-01,\n",
      "        -2.2519e-01, -4.1312e-02,  1.2412e-02,  9.9100e-02, -1.9262e-01,\n",
      "         1.8239e-01,  2.2099e-01, -4.7019e-02, -2.9656e-01,  2.3189e-01,\n",
      "        -2.4933e-01,  3.5279e-01,  6.5004e-01, -2.6823e-02,  5.0739e-01,\n",
      "         2.5138e-01,  3.8867e-01, -2.7740e-01,  3.0047e-02,  2.2249e-01,\n",
      "        -2.7251e-02, -1.5716e-01, -5.0113e-01,  2.9801e-02,  3.4823e-01,\n",
      "         2.3441e-01, -3.0995e-01, -4.4104e-01, -2.9397e-01, -6.3907e-01,\n",
      "        -4.7920e-01, -5.4805e-01,  5.0674e-03,  9.0554e-02, -1.1664e-01,\n",
      "        -2.7590e-01,  4.4132e-01, -2.4992e-01,  4.2737e-01, -1.7768e-01,\n",
      "        -3.6470e-01,  1.8215e-01, -5.0205e-02,  1.6772e-01,  5.2318e-01,\n",
      "        -2.7701e-01, -1.8868e-01,  4.6431e-01, -7.5286e-02, -4.5150e-01,\n",
      "        -1.3110e-03, -2.3798e-01,  1.5602e-01,  2.5875e-01, -1.8911e-01,\n",
      "        -3.5669e-01, -2.8060e-01, -9.3981e-02,  1.9642e-01,  1.4115e-01,\n",
      "        -1.6324e+00, -1.9501e-01,  3.0758e-01,  1.8041e-01,  8.3262e-01,\n",
      "        -3.9934e-01,  3.9158e-02,  3.9458e-01, -6.0580e-02,  1.2076e-01,\n",
      "        -5.7896e-01,  6.0514e-01, -2.0605e-03,  1.9928e-01,  4.4039e-01,\n",
      "         4.5088e-02,  2.4489e-01,  1.9855e-01, -2.9973e-02, -3.0880e-01,\n",
      "        -3.6730e-01, -5.2906e-02,  1.2316e-01,  1.5000e-02,  2.1403e-04,\n",
      "        -3.0821e-01, -6.7856e-02,  2.5868e-01, -3.8208e-03,  4.6086e-02,\n",
      "         1.7753e-01, -6.6423e-01,  1.7526e-01,  6.2497e-02,  4.3254e-01,\n",
      "         4.1094e-01,  2.2801e-01,  1.7726e-01, -6.5866e-02,  3.0953e-01,\n",
      "        -3.4120e-01,  2.5817e-01,  6.1135e-01, -9.5031e-02, -1.2664e-01,\n",
      "         1.1888e-01,  6.3210e-03, -8.5264e-02,  4.4389e-01, -2.4888e-01,\n",
      "        -1.0868e-01,  3.1034e-02,  1.1978e-01, -3.8344e-01, -2.1949e-01,\n",
      "        -1.6579e-01,  4.2732e-04, -5.3004e-02, -2.6614e-01,  1.5393e-01,\n",
      "         4.0862e-01,  8.4975e-02,  3.4834e-02, -4.0866e-01, -2.6732e-01,\n",
      "        -3.7444e-01,  4.2639e-01, -2.9412e-02, -2.8105e-01,  3.0112e-01,\n",
      "         2.1948e-01,  5.8920e-01, -8.6683e-01, -1.7219e-01, -2.4834e-01,\n",
      "        -3.6890e-02,  2.2020e-01,  5.1780e-01,  2.0315e-01, -3.5326e-01,\n",
      "         5.2588e-01, -6.0909e-01, -3.0589e-01,  6.0547e-01, -1.0019e-01,\n",
      "         9.3938e-03,  7.7509e-02,  1.5841e-01,  2.8500e-01,  2.7054e-01,\n",
      "        -5.8667e-01, -5.5491e-01,  2.0272e-01, -2.7360e-02,  4.9081e-02,\n",
      "        -1.4209e-01, -1.0127e-01, -2.1315e-01, -2.4780e-01,  6.0909e-02,\n",
      "         6.9626e-02,  3.3659e-01,  1.8385e-01,  1.4970e-01,  2.4684e-01,\n",
      "         7.3434e-01,  4.4321e-01, -1.4962e-01, -5.9188e-01, -1.4932e-02,\n",
      "         1.3305e-01, -1.4133e-01, -1.4336e-02,  8.9345e-02,  2.6609e-01,\n",
      "        -4.3073e-01,  4.1756e-01, -4.5123e-01,  1.2461e+00, -6.5148e-02,\n",
      "         2.5528e-01,  5.1980e-02, -1.0902e-01, -1.8703e-01, -2.2202e-01,\n",
      "        -5.3633e-01,  5.4564e-01,  1.8318e-01, -7.2051e-01,  2.7426e-01,\n",
      "        -1.8174e-01, -1.3185e-01,  4.7327e-01,  5.6593e-01, -5.6727e-02,\n",
      "        -2.8119e-01, -3.0372e-01, -6.9560e-02, -2.9197e-01,  1.8352e-01,\n",
      "         5.9370e-01, -1.3101e-01, -3.5140e-01,  2.1617e-01, -1.1486e-02,\n",
      "        -1.2662e-01, -4.4047e-01,  2.3261e-01,  3.1829e-01,  7.6459e-02,\n",
      "         3.3381e-01,  2.1479e-01,  2.0257e-01,  1.1408e-01, -2.3951e-01,\n",
      "        -3.4999e-01, -3.4994e-01,  5.0292e-01,  1.7371e-01,  9.9013e-02,\n",
      "         7.7521e-01,  1.3519e-01,  3.4963e-02,  3.4709e-01,  2.8635e-01,\n",
      "        -3.3356e-01, -2.2552e-01,  6.6402e-01,  1.1299e-01, -2.9142e-01,\n",
      "         8.7899e-02, -3.8532e-01, -1.3561e-01,  1.7180e-01, -3.9792e-01,\n",
      "        -5.8804e-01, -7.3743e-01,  1.9728e-01, -3.0639e-01, -4.6778e-02,\n",
      "         6.9955e-01, -5.9940e-01, -2.8185e-01, -6.4041e-02,  2.2043e-01,\n",
      "        -1.0892e-01,  1.8480e-02, -4.0422e-01, -9.4659e-02,  4.5424e-01,\n",
      "         1.3237e-01,  1.9246e-01,  1.7695e-01,  4.2342e-01,  2.0092e-01,\n",
      "        -4.7413e-01, -6.4427e-01, -1.3117e+00,  2.2838e-02, -9.0915e-02,\n",
      "         9.5776e-02, -1.5119e-01,  2.2204e-01, -2.6011e-01,  9.7749e-02,\n",
      "         4.3922e-01,  2.6065e-01, -5.0626e-02,  6.2134e-01, -7.7047e-02,\n",
      "        -3.5368e-01,  6.9146e-02,  1.2242e-01,  1.6030e-01, -9.7673e-02,\n",
      "        -1.0633e-01, -1.0303e-01,  6.4106e-02, -2.4737e-01, -3.3115e-01,\n",
      "        -9.0640e-02, -2.2469e-01,  1.8741e-01,  4.3365e-01, -2.1852e-01,\n",
      "         2.6592e-01, -1.1213e-01,  1.5461e-02,  1.2314e-01, -1.3872e-01,\n",
      "        -2.7384e-02,  1.2700e-01, -1.1627e-01,  3.1852e-01,  1.5174e-01,\n",
      "         2.3110e-01,  4.0482e-01,  1.7731e-01,  8.4531e-01, -4.1546e-01,\n",
      "         5.0087e-01, -2.4786e-01, -1.6288e-01,  1.7745e-01, -2.7294e-01,\n",
      "         7.0121e-01, -5.4478e-01, -3.5465e-01, -1.1867e-01,  9.0794e-02,\n",
      "         2.5614e-01,  2.3399e-01,  1.0483e-02, -1.8584e-01, -9.2691e-02,\n",
      "        -1.2548e-01, -1.7227e-01, -7.4417e-01, -5.6606e-01, -3.5125e-01,\n",
      "         1.2164e-02,  2.3935e-01, -1.9064e-01, -4.5563e-03,  4.7771e-01,\n",
      "        -6.2012e-02, -3.5842e-01,  5.0698e-04,  1.0899e-02,  1.2609e-01,\n",
      "         1.6684e-01,  2.1349e-01, -5.5345e-02,  1.1511e-01,  1.9937e-01,\n",
      "         4.0411e-01,  3.5007e-01, -1.8313e-01,  2.9078e-01,  4.4221e-01,\n",
      "         5.7630e-01,  2.9493e-01, -3.7460e+00, -3.4536e-01,  4.1481e-01,\n",
      "         1.4181e-01,  2.6919e-02, -3.5338e-01, -2.6630e-01, -1.3722e-01,\n",
      "        -9.9917e-02,  5.2861e-02,  9.9656e-02, -5.1425e-01, -2.3103e-01,\n",
      "        -4.0260e-02,  5.5750e-01, -1.4120e-01], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(op[0][-1][:,0,:][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7763, -0.4299, -0.9290,  ..., -0.6874, -0.6675,  0.7268],\n",
       "        [-0.6634, -0.3750, -0.9179,  ..., -0.7056, -0.6269,  0.5975],\n",
       "        [-0.6469, -0.3415, -0.9396,  ..., -0.6685, -0.5531,  0.7790]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do you consider yourself attractive?',\n",
       " 'Do you consider yourself attractive?',\n",
       " 'How should I kiss my girlfriend for the first time?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7763, -0.4299, -0.9290,  ..., -0.6874, -0.6675,  0.7268],\n",
       "        [-0.6634, -0.3750, -0.9179,  ..., -0.7056, -0.6269,  0.5975],\n",
       "        [-0.6469, -0.3415, -0.9396,  ..., -0.6685, -0.5531,  0.7790]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  101,  2129,  2079,  1045,  3967,  1037,  2613, 23307,  1029,   102,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  101,  2129,  2079,  1045,  3967,  1037,  2613, 23307,  1029,   102,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [  101,  2073,  2071,  1045,  2424,  1037, 17371,  3638,  4003,  2951,\n",
      "           7233,  4007,  2489,  1997,  3465,  1029,   102,     0,     0,     0]]])\n",
      "tensor([[ 101, 2054, 2024, 2070, 1997, 1996, 2190, 4219, 3784, 2000, 4553, 2446,\n",
      "         1029,  102,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 2054, 2024, 2070, 1997, 1996, 2190, 4219, 3784, 2000, 4553, 2446,\n",
      "         1029,  102,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 2129, 2079, 1045, 2131, 3825, 2005, 3015, 1029,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for _, i in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "    print(i)\n",
    "    print(test_trip_toks[0])\n",
    "    break\n",
    "#     op = bert(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/144 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|          | 1/144 [00:01<02:34,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|▏         | 2/144 [00:01<02:17,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   2%|▏         | 3/144 [00:02<01:44,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 4/144 [00:02<01:25,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 5/144 [00:03<01:14,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   4%|▍         | 6/144 [00:03<01:07,  2.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▍         | 7/144 [00:04<01:03,  2.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▌         | 8/144 [00:04<01:00,  2.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▋         | 9/144 [00:04<00:58,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   7%|▋         | 10/144 [00:05<00:56,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 11/144 [00:05<00:54,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 12/144 [00:06<00:54,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   9%|▉         | 13/144 [00:06<00:53,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|▉         | 14/144 [00:06<00:53,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|█         | 15/144 [00:07<00:52,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  11%|█         | 16/144 [00:07<00:51,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▏        | 17/144 [00:08<00:50,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▎        | 18/144 [00:08<00:49,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  13%|█▎        | 19/144 [00:08<00:48,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  14%|█▍        | 20/144 [00:09<00:48,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▍        | 21/144 [00:09<00:47,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▌        | 22/144 [00:10<00:48,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  16%|█▌        | 23/144 [00:10<00:48,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 24/144 [00:10<00:49,  2.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 25/144 [00:11<00:52,  2.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  18%|█▊        | 26/144 [00:11<00:51,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 27/144 [00:12<00:49,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 28/144 [00:12<00:47,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  20%|██        | 29/144 [00:12<00:46,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  21%|██        | 30/144 [00:13<00:45,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 31/144 [00:13<00:44,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 32/144 [00:14<00:43,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  23%|██▎       | 33/144 [00:14<00:43,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▎       | 34/144 [00:14<00:42,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▍       | 35/144 [00:15<00:42,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  25%|██▌       | 36/144 [00:15<00:42,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▌       | 37/144 [00:16<00:43,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▋       | 38/144 [00:16<00:42,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  27%|██▋       | 39/144 [00:16<00:42,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 40/144 [00:17<00:41,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 41/144 [00:17<00:40,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  29%|██▉       | 42/144 [00:18<00:39,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  30%|██▉       | 43/144 [00:18<00:39,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███       | 44/144 [00:18<00:38,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███▏      | 45/144 [00:19<00:38,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  32%|███▏      | 46/144 [00:19<00:37,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 47/144 [00:20<00:37,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 48/144 [00:20<00:36,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  34%|███▍      | 49/144 [00:20<00:36,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▍      | 50/144 [00:21<00:36,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▌      | 51/144 [00:21<00:36,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  36%|███▌      | 52/144 [00:22<00:37,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  37%|███▋      | 53/144 [00:22<00:37,  2.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 54/144 [00:22<00:37,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 55/144 [00:23<00:36,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  39%|███▉      | 56/144 [00:23<00:35,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|███▉      | 57/144 [00:24<00:34,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|████      | 58/144 [00:24<00:34,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  41%|████      | 59/144 [00:24<00:33,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 60/144 [00:25<00:32,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 61/144 [00:25<00:32,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  43%|████▎     | 62/144 [00:25<00:31,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 63/144 [00:26<00:30,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 64/144 [00:26<00:30,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  45%|████▌     | 65/144 [00:27<00:30,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  46%|████▌     | 66/144 [00:27<00:30,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 67/144 [00:27<00:29,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 68/144 [00:28<00:30,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  48%|████▊     | 69/144 [00:28<00:31,  2.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▊     | 70/144 [00:29<00:31,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▉     | 71/144 [00:29<00:29,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  50%|█████     | 72/144 [00:29<00:28,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████     | 73/144 [00:30<00:28,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████▏    | 74/144 [00:30<00:27,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  52%|█████▏    | 75/144 [00:31<00:26,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 76/144 [00:31<00:26,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 77/144 [00:31<00:26,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  54%|█████▍    | 78/144 [00:32<00:25,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  55%|█████▍    | 79/144 [00:32<00:25,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▌    | 80/144 [00:33<00:26,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▋    | 81/144 [00:33<00:26,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  57%|█████▋    | 82/144 [00:34<00:26,  2.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 83/144 [00:34<00:25,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 84/144 [00:34<00:25,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  59%|█████▉    | 85/144 [00:35<00:24,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|█████▉    | 86/144 [00:35<00:23,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|██████    | 87/144 [00:36<00:22,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  61%|██████    | 88/144 [00:36<00:22,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▏   | 89/144 [00:36<00:22,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▎   | 90/144 [00:37<00:22,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  63%|██████▎   | 91/144 [00:37<00:22,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  64%|██████▍   | 92/144 [00:38<00:21,  2.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▍   | 93/144 [00:38<00:20,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▌   | 94/144 [00:38<00:19,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  66%|██████▌   | 95/144 [00:39<00:19,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 96/144 [00:39<00:18,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 97/144 [00:40<00:18,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  68%|██████▊   | 98/144 [00:40<00:17,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 99/144 [00:40<00:17,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 100/144 [00:41<00:17,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  70%|███████   | 101/144 [00:41<00:16,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  71%|███████   | 102/144 [00:42<00:16,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 103/144 [00:42<00:16,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 104/144 [00:42<00:16,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  73%|███████▎  | 105/144 [00:43<00:15,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▎  | 106/144 [00:43<00:16,  2.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▍  | 107/144 [00:44<00:15,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  75%|███████▌  | 108/144 [00:44<00:14,  2.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▌  | 109/144 [00:44<00:14,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▋  | 110/144 [00:45<00:13,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  77%|███████▋  | 111/144 [00:45<00:13,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 112/144 [00:46<00:12,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 113/144 [00:46<00:12,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  79%|███████▉  | 114/144 [00:46<00:11,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  80%|███████▉  | 115/144 [00:47<00:11,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████  | 116/144 [00:47<00:10,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████▏ | 117/144 [00:47<00:10,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  82%|████████▏ | 118/144 [00:48<00:09,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 119/144 [00:48<00:09,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 120/144 [00:49<00:09,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  84%|████████▍ | 121/144 [00:49<00:09,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▍ | 122/144 [00:50<00:08,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▌ | 123/144 [00:50<00:08,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  86%|████████▌ | 124/144 [00:50<00:07,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  87%|████████▋ | 125/144 [00:51<00:07,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 126/144 [00:51<00:06,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 127/144 [00:51<00:06,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  89%|████████▉ | 128/144 [00:52<00:06,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|████████▉ | 129/144 [00:52<00:05,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|█████████ | 130/144 [00:53<00:05,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  91%|█████████ | 131/144 [00:53<00:04,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 132/144 [00:53<00:04,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 133/144 [00:54<00:04,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  93%|█████████▎| 134/144 [00:54<00:03,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 135/144 [00:55<00:03,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 136/144 [00:55<00:03,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  95%|█████████▌| 137/144 [00:55<00:02,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  96%|█████████▌| 138/144 [00:56<00:02,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 139/144 [00:56<00:01,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 140/144 [00:56<00:01,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  98%|█████████▊| 141/144 [00:57<00:01,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▊| 142/144 [00:57<00:00,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▉| 143/144 [00:58<00:00,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 144/144 [00:58<00:00,  2.59it/s]\u001b[A\n",
      "Epochs:  33%|███▎      | 1/3 [00:58<01:57, 58.56s/it]      \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3 - Loss: 4.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/144 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|          | 1/144 [00:01<04:09,  1.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|▏         | 2/144 [00:02<02:15,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   2%|▏         | 3/144 [00:02<01:37,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 4/144 [00:02<01:19,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 5/144 [00:03<01:08,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   4%|▍         | 6/144 [00:03<01:02,  2.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▍         | 7/144 [00:04<00:58,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▌         | 8/144 [00:04<00:55,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▋         | 9/144 [00:04<00:53,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   7%|▋         | 10/144 [00:05<00:52,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 11/144 [00:05<00:52,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 12/144 [00:05<00:52,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   9%|▉         | 13/144 [00:06<00:51,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|▉         | 14/144 [00:06<00:53,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|█         | 15/144 [00:07<00:54,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  11%|█         | 16/144 [00:07<01:01,  2.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▏        | 17/144 [00:08<00:58,  2.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▎        | 18/144 [00:08<00:54,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  13%|█▎        | 19/144 [00:09<00:52,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  14%|█▍        | 20/144 [00:09<00:51,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▍        | 21/144 [00:09<00:49,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▌        | 22/144 [00:10<00:48,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  16%|█▌        | 23/144 [00:10<00:47,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 24/144 [00:10<00:47,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 25/144 [00:11<00:48,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  18%|█▊        | 26/144 [00:11<00:49,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 27/144 [00:12<00:48,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 28/144 [00:12<00:46,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  20%|██        | 29/144 [00:13<00:46,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  21%|██        | 30/144 [00:13<00:44,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 31/144 [00:13<00:45,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 32/144 [00:14<00:47,  2.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  23%|██▎       | 33/144 [00:14<00:49,  2.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▎       | 34/144 [00:15<00:47,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▍       | 35/144 [00:15<00:46,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  25%|██▌       | 36/144 [00:16<00:45,  2.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▌       | 37/144 [00:16<00:43,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▋       | 38/144 [00:16<00:42,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  27%|██▋       | 39/144 [00:17<00:43,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 40/144 [00:17<00:44,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 41/144 [00:18<00:42,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  29%|██▉       | 42/144 [00:18<00:40,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  30%|██▉       | 43/144 [00:18<00:38,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███       | 44/144 [00:19<00:38,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███▏      | 45/144 [00:19<00:37,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  32%|███▏      | 46/144 [00:19<00:37,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 47/144 [00:20<00:37,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 48/144 [00:20<00:37,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  34%|███▍      | 49/144 [00:21<00:36,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▍      | 50/144 [00:21<00:36,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▌      | 51/144 [00:21<00:36,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  36%|███▌      | 52/144 [00:22<00:36,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  37%|███▋      | 53/144 [00:22<00:34,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 54/144 [00:22<00:33,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 55/144 [00:23<00:33,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  39%|███▉      | 56/144 [00:23<00:33,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|███▉      | 57/144 [00:24<00:33,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|████      | 58/144 [00:24<00:32,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  41%|████      | 59/144 [00:24<00:31,  2.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 60/144 [00:25<00:32,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 61/144 [00:25<00:31,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  43%|████▎     | 62/144 [00:26<00:31,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 63/144 [00:26<00:32,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 64/144 [00:26<00:33,  2.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  45%|████▌     | 65/144 [00:27<00:33,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  46%|████▌     | 66/144 [00:27<00:31,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 67/144 [00:28<00:30,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 68/144 [00:28<00:29,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  48%|████▊     | 69/144 [00:28<00:29,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▊     | 70/144 [00:29<00:28,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▉     | 71/144 [00:29<00:27,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  50%|█████     | 72/144 [00:29<00:27,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████     | 73/144 [00:30<00:26,  2.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████▏    | 74/144 [00:30<00:26,  2.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  52%|█████▏    | 75/144 [00:31<00:26,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 76/144 [00:31<00:25,  2.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 77/144 [00:31<00:25,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  54%|█████▍    | 78/144 [00:32<00:24,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  55%|█████▍    | 79/144 [00:32<00:24,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▌    | 80/144 [00:33<00:24,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▋    | 81/144 [00:33<00:24,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  57%|█████▋    | 82/144 [00:33<00:23,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 83/144 [00:34<00:23,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 84/144 [00:34<00:22,  2.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  59%|█████▉    | 85/144 [00:34<00:21,  2.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|█████▉    | 86/144 [00:35<00:21,  2.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|██████    | 87/144 [00:35<00:21,  2.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  61%|██████    | 88/144 [00:36<00:21,  2.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▏   | 89/144 [00:36<00:20,  2.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▎   | 90/144 [00:36<00:20,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  63%|██████▎   | 91/144 [00:37<00:20,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  64%|██████▍   | 92/144 [00:37<00:19,  2.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▍   | 93/144 [00:37<00:19,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▌   | 94/144 [00:38<00:19,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  66%|██████▌   | 95/144 [00:38<00:18,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 96/144 [00:39<00:18,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 97/144 [00:39<00:18,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  68%|██████▊   | 98/144 [00:39<00:18,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 99/144 [00:40<00:18,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 100/144 [00:40<00:17,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  70%|███████   | 101/144 [00:41<00:16,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  71%|███████   | 102/144 [00:41<00:16,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 103/144 [00:41<00:15,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 104/144 [00:42<00:15,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  73%|███████▎  | 105/144 [00:42<00:14,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▎  | 106/144 [00:42<00:14,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▍  | 107/144 [00:43<00:13,  2.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  75%|███████▌  | 108/144 [00:43<00:13,  2.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▌  | 109/144 [00:44<00:13,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▋  | 110/144 [00:44<00:12,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  77%|███████▋  | 111/144 [00:44<00:12,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 112/144 [00:45<00:12,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 113/144 [00:45<00:11,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  79%|███████▉  | 114/144 [00:45<00:11,  2.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  80%|███████▉  | 115/144 [00:46<00:11,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████  | 116/144 [00:46<00:10,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████▏ | 117/144 [00:47<00:10,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  82%|████████▏ | 118/144 [00:47<00:10,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 119/144 [00:48<00:10,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 120/144 [00:48<00:09,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  84%|████████▍ | 121/144 [00:48<00:09,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▍ | 122/144 [00:49<00:08,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▌ | 123/144 [00:49<00:08,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  86%|████████▌ | 124/144 [00:49<00:07,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  87%|████████▋ | 125/144 [00:50<00:07,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 126/144 [00:50<00:06,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 127/144 [00:51<00:06,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  89%|████████▉ | 128/144 [00:51<00:06,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|████████▉ | 129/144 [00:51<00:05,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|█████████ | 130/144 [00:52<00:05,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  91%|█████████ | 131/144 [00:52<00:04,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 132/144 [00:53<00:04,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 133/144 [00:53<00:04,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  93%|█████████▎| 134/144 [00:53<00:03,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 135/144 [00:54<00:03,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 136/144 [00:54<00:03,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  95%|█████████▌| 137/144 [00:54<00:02,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  96%|█████████▌| 138/144 [00:55<00:02,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 139/144 [00:55<00:01,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 140/144 [00:56<00:01,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  98%|█████████▊| 141/144 [00:56<00:01,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▊| 142/144 [00:56<00:00,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▉| 143/144 [00:57<00:00,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 144/144 [00:57<00:00,  2.58it/s]\u001b[A\n",
      "Epochs:  67%|██████▋   | 2/3 [01:56<00:58, 58.07s/it]      \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/3 - Loss: 5.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/144 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|          | 1/144 [00:01<03:57,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   1%|▏         | 2/144 [00:02<02:22,  1.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   2%|▏         | 3/144 [00:02<01:41,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 4/144 [00:02<01:22,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   3%|▎         | 5/144 [00:03<01:11,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   4%|▍         | 6/144 [00:03<01:04,  2.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   5%|▍         | 7/144 [00:04<01:00,  2.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▌         | 8/144 [00:04<00:59,  2.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   6%|▋         | 9/144 [00:04<00:59,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   7%|▋         | 10/144 [00:05<00:57,  2.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 11/144 [00:05<00:55,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   8%|▊         | 12/144 [00:06<00:54,  2.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   9%|▉         | 13/144 [00:06<00:53,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|▉         | 14/144 [00:06<00:52,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  10%|█         | 15/144 [00:07<00:50,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  11%|█         | 16/144 [00:07<00:49,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▏        | 17/144 [00:08<00:49,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  12%|█▎        | 18/144 [00:08<00:48,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  13%|█▎        | 19/144 [00:08<00:48,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  14%|█▍        | 20/144 [00:09<00:47,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▍        | 21/144 [00:09<00:47,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  15%|█▌        | 22/144 [00:10<00:46,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  16%|█▌        | 23/144 [00:10<00:46,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 24/144 [00:10<00:46,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  17%|█▋        | 25/144 [00:11<00:45,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  18%|█▊        | 26/144 [00:11<00:45,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 27/144 [00:11<00:44,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  19%|█▉        | 28/144 [00:12<00:44,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  20%|██        | 29/144 [00:12<00:44,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  21%|██        | 30/144 [00:13<00:43,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 31/144 [00:13<00:44,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  22%|██▏       | 32/144 [00:13<00:44,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  23%|██▎       | 33/144 [00:14<00:43,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▎       | 34/144 [00:14<00:42,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  24%|██▍       | 35/144 [00:15<00:42,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  25%|██▌       | 36/144 [00:15<00:42,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▌       | 37/144 [00:15<00:42,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  26%|██▋       | 38/144 [00:16<00:41,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  27%|██▋       | 39/144 [00:16<00:40,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 40/144 [00:17<00:40,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  28%|██▊       | 41/144 [00:17<00:39,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  29%|██▉       | 42/144 [00:17<00:39,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  30%|██▉       | 43/144 [00:18<00:38,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███       | 44/144 [00:18<00:37,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  31%|███▏      | 45/144 [00:18<00:38,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  32%|███▏      | 46/144 [00:19<00:37,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 47/144 [00:19<00:37,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  33%|███▎      | 48/144 [00:20<00:37,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  34%|███▍      | 49/144 [00:20<00:36,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▍      | 50/144 [00:20<00:36,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  35%|███▌      | 51/144 [00:21<00:35,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  36%|███▌      | 52/144 [00:21<00:35,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  37%|███▋      | 53/144 [00:22<00:34,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 54/144 [00:22<00:34,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  38%|███▊      | 55/144 [00:22<00:33,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  39%|███▉      | 56/144 [00:23<00:33,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|███▉      | 57/144 [00:23<00:32,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  40%|████      | 58/144 [00:23<00:33,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  41%|████      | 59/144 [00:24<00:33,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 60/144 [00:24<00:32,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  42%|████▏     | 61/144 [00:25<00:32,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  43%|████▎     | 62/144 [00:25<00:31,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 63/144 [00:25<00:31,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  44%|████▍     | 64/144 [00:26<00:31,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  45%|████▌     | 65/144 [00:26<00:30,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  46%|████▌     | 66/144 [00:27<00:29,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 67/144 [00:27<00:29,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  47%|████▋     | 68/144 [00:27<00:29,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  48%|████▊     | 69/144 [00:28<00:28,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▊     | 70/144 [00:28<00:28,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  49%|████▉     | 71/144 [00:28<00:27,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  50%|█████     | 72/144 [00:29<00:27,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████     | 73/144 [00:29<00:27,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  51%|█████▏    | 74/144 [00:30<00:26,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  52%|█████▏    | 75/144 [00:30<00:26,  2.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 76/144 [00:30<00:25,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  53%|█████▎    | 77/144 [00:31<00:25,  2.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  54%|█████▍    | 78/144 [00:31<00:27,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  55%|█████▍    | 79/144 [00:32<00:27,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▌    | 80/144 [00:32<00:27,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  56%|█████▋    | 81/144 [00:32<00:26,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  57%|█████▋    | 82/144 [00:33<00:25,  2.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 83/144 [00:33<00:24,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  58%|█████▊    | 84/144 [00:34<00:23,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  59%|█████▉    | 85/144 [00:34<00:23,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|█████▉    | 86/144 [00:34<00:22,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  60%|██████    | 87/144 [00:35<00:22,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  61%|██████    | 88/144 [00:35<00:21,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▏   | 89/144 [00:36<00:21,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  62%|██████▎   | 90/144 [00:36<00:20,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  63%|██████▎   | 91/144 [00:36<00:20,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  64%|██████▍   | 92/144 [00:37<00:19,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▍   | 93/144 [00:37<00:19,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  65%|██████▌   | 94/144 [00:37<00:19,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  66%|██████▌   | 95/144 [00:38<00:19,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 96/144 [00:38<00:19,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  67%|██████▋   | 97/144 [00:39<00:18,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  68%|██████▊   | 98/144 [00:39<00:17,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 99/144 [00:39<00:17,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  69%|██████▉   | 100/144 [00:40<00:17,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  70%|███████   | 101/144 [00:40<00:16,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  71%|███████   | 102/144 [00:41<00:16,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 103/144 [00:41<00:16,  2.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  72%|███████▏  | 104/144 [00:41<00:15,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  73%|███████▎  | 105/144 [00:42<00:15,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▎  | 106/144 [00:42<00:15,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  74%|███████▍  | 107/144 [00:43<00:15,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  75%|███████▌  | 108/144 [00:43<00:15,  2.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▌  | 109/144 [00:44<00:14,  2.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  76%|███████▋  | 110/144 [00:44<00:13,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  77%|███████▋  | 111/144 [00:44<00:13,  2.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 112/144 [00:45<00:12,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  78%|███████▊  | 113/144 [00:45<00:12,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  79%|███████▉  | 114/144 [00:45<00:11,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  80%|███████▉  | 115/144 [00:46<00:11,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████  | 116/144 [00:46<00:10,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  81%|████████▏ | 117/144 [00:47<00:10,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  82%|████████▏ | 118/144 [00:47<00:09,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 119/144 [00:47<00:10,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  83%|████████▎ | 120/144 [00:48<00:09,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  84%|████████▍ | 121/144 [00:48<00:09,  2.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▍ | 122/144 [00:49<00:09,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  85%|████████▌ | 123/144 [00:49<00:08,  2.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  86%|████████▌ | 124/144 [00:50<00:07,  2.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  87%|████████▋ | 125/144 [00:50<00:07,  2.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 126/144 [00:50<00:06,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  88%|████████▊ | 127/144 [00:51<00:06,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  89%|████████▉ | 128/144 [00:51<00:06,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|████████▉ | 129/144 [00:51<00:05,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|█████████ | 130/144 [00:52<00:05,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  91%|█████████ | 131/144 [00:52<00:05,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 132/144 [00:53<00:04,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  92%|█████████▏| 133/144 [00:53<00:04,  2.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  93%|█████████▎| 134/144 [00:53<00:03,  2.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 135/144 [00:54<00:03,  2.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  94%|█████████▍| 136/144 [00:54<00:03,  2.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  95%|█████████▌| 137/144 [00:55<00:02,  2.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  96%|█████████▌| 138/144 [00:55<00:02,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 139/144 [00:55<00:02,  2.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  97%|█████████▋| 140/144 [00:56<00:01,  2.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  98%|█████████▊| 141/144 [00:56<00:01,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▊| 142/144 [00:57<00:00,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  99%|█████████▉| 143/144 [00:57<00:00,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|██████████| 144/144 [00:57<00:00,  2.54it/s]\u001b[A\n",
      "Epochs: 100%|██████████| 3/3 [02:54<00:00, 58.07s/it]      \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/3 - Loss: 6.5370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    running_loss = []\n",
    "    for step, txt_pcs in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "        txt_pcs = txt_pcs[0]\n",
    "#         anchor_txt = txt_pcs[0][0,:]\n",
    "#         positive_txt = txt_pcs[0][1,:]\n",
    "#         negative_txt = txt_pcs[0][2,:]\n",
    "#         anchor_txt = anchor_txt.to(device)\n",
    "#         positive_txt = positive_txt.to(device)\n",
    "#         negative_txt = negative_txt.to(device)\n",
    "#         single_instance = [anchor_txt, positive_txt, negative_txt]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model_op = model(txt_pcs)\n",
    "        anchor_out = model_op[0][-1][:,0,:][0]\n",
    "        positive_out = model_op[0][-1][:,0,:][1] #model(positive_txt)\n",
    "        negative_out = model_op[0][-1][:,0,:][2] #model(negative_txt)\n",
    "        \n",
    "        print(anchor_out.shape, negative_out.shape)\n",
    "        \n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
       "          4434,  2096,  2478,  1037, 21210,  2078,  1029,   102],\n",
       "        [  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
       "          4434,   102,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_text = torch.tensor(tokenizer.batch_encode_plus(data_batch, pad_to_max_length=True)['input_ids'])\n",
    "tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
       "          4434,  2096,  2478,  1037, 21210,  2078,  1029,   102]),\n",
       " tensor([ 101, 2129, 2064, 1045, 3623, 1996, 3177, 1997, 2026, 4274, 4434,  102,\n",
       "            0,    0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_text.shape\n",
    "tok_text[0], tok_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = bert(tok_text)\n",
    "type(op), len(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 12, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(op[0]), len(op[0]), len(op[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.1794,  0.2469, -0.0790,  ...,  0.0424,  0.0461,  0.0859],\n",
       "           [-0.2570,  1.5673, -1.4244,  ..., -0.1042,  0.6053,  0.5434],\n",
       "           [ 1.2409, -0.4284,  0.2041,  ..., -0.6638,  0.5053, -1.4993],\n",
       "           ...,\n",
       "           [-0.5067, -0.8269,  0.1051,  ..., -0.9189, -0.1751,  0.2254],\n",
       "           [ 0.5423,  0.0294, -0.6308,  ...,  0.3701,  0.5269,  1.0042],\n",
       "           [-0.0452,  0.0536,  0.1051,  ..., -0.2519,  0.0201, -0.1321]],\n",
       "  \n",
       "          [[ 0.2086, -0.0878, -0.1736,  ...,  0.0230,  0.0755,  0.1805],\n",
       "           [ 0.0699,  1.6820, -1.2459,  ...,  0.5651, -0.2337,  0.1825],\n",
       "           [ 1.2176, -0.2480,  0.3136,  ..., -1.2115,  0.3101, -1.1016],\n",
       "           ...,\n",
       "           [ 0.0293, -0.0316,  0.2374,  ...,  0.3078, -0.3459,  0.4025],\n",
       "           [-0.0866,  0.0057,  0.2624,  ...,  0.0565,  0.2232,  0.2352],\n",
       "           [ 0.0463, -0.0772,  0.2613,  ...,  0.1003, -0.2641,  0.2848]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 1.4097e-01, -4.5585e-02, -1.9856e-01,  ...,  1.0280e-01,\n",
       "             2.5573e-01, -5.4002e-02],\n",
       "           [-8.0941e-03,  2.0326e+00, -8.9665e-01,  ..., -1.8989e-01,\n",
       "             5.7303e-01,  3.4799e-01],\n",
       "           [ 8.5595e-01, -4.7294e-01,  7.9350e-01,  ..., -1.3160e+00,\n",
       "             8.5059e-01, -1.8365e+00],\n",
       "           ...,\n",
       "           [ 3.2628e-01, -7.2738e-01,  3.9092e-01,  ..., -8.2318e-01,\n",
       "            -1.8477e-01, -5.0089e-01],\n",
       "           [ 3.5948e-01,  7.3920e-02, -2.0956e-01,  ..., -3.9965e-03,\n",
       "             4.6489e-01,  1.1513e+00],\n",
       "           [-1.9767e-01,  1.2040e-02,  1.9876e-01,  ..., -1.9703e-01,\n",
       "             2.3544e-02, -1.2142e-01]],\n",
       "  \n",
       "          [[ 1.0655e-01, -1.2843e-01, -2.8645e-01,  ...,  2.5315e-02,\n",
       "             1.5794e-01,  1.2935e-01],\n",
       "           [ 1.1414e-01,  1.4814e+00, -9.3800e-01,  ...,  4.1397e-01,\n",
       "            -2.5857e-01,  4.8736e-01],\n",
       "           [ 1.0619e+00, -1.6295e-01,  4.8549e-01,  ..., -9.2286e-01,\n",
       "             8.3523e-01, -1.5734e+00],\n",
       "           ...,\n",
       "           [ 1.9226e-02, -6.9819e-02,  7.8150e-01,  ...,  3.4782e-01,\n",
       "            -2.8367e-01,  4.5345e-01],\n",
       "           [ 2.7351e-03,  7.9537e-02,  7.3150e-01,  ..., -1.3186e-01,\n",
       "             1.8675e-01,  1.8531e-02],\n",
       "           [ 9.5899e-02,  9.0588e-02,  6.0345e-01,  ...,  8.7103e-02,\n",
       "            -3.0899e-01,  1.6464e-03]]], grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 2.0376e-01, -2.2111e-01, -1.0449e-01,  ...,  1.9672e-01,\n",
       "             1.9065e-01,  1.1126e-01],\n",
       "           [-3.0803e-01,  1.5078e+00, -3.6632e-01,  ..., -3.0399e-01,\n",
       "             4.5968e-01,  4.2131e-01],\n",
       "           [ 5.0836e-01, -4.5290e-01,  6.4817e-01,  ..., -1.5975e+00,\n",
       "             7.7538e-01, -1.5182e+00],\n",
       "           ...,\n",
       "           [ 5.3020e-01, -6.3872e-01,  2.2973e-01,  ..., -1.3112e+00,\n",
       "            -1.1744e-01, -4.2500e-01],\n",
       "           [ 4.7719e-01, -6.0496e-03,  4.4358e-02,  ...,  4.0695e-01,\n",
       "             2.3382e-01,  6.7678e-01],\n",
       "           [-6.1247e-02, -7.9948e-02,  1.1739e-01,  ...,  2.4069e-02,\n",
       "             2.3677e-02,  8.0586e-04]],\n",
       "  \n",
       "          [[ 5.4716e-02, -1.1250e-01, -2.2960e-01,  ...,  3.6716e-02,\n",
       "             1.7380e-01,  1.3453e-01],\n",
       "           [-4.1658e-01,  1.2349e+00, -5.1986e-01,  ...,  1.1263e-01,\n",
       "            -3.5493e-01,  5.1753e-01],\n",
       "           [ 7.8878e-01, -2.6034e-01,  2.8963e-01,  ..., -1.0483e+00,\n",
       "             3.5042e-01, -1.0584e+00],\n",
       "           ...,\n",
       "           [-2.6029e-01, -1.0650e-01,  7.7377e-01,  ...,  2.0586e-01,\n",
       "            -1.7903e-01,  3.1254e-01],\n",
       "           [-3.4611e-01, -6.1328e-02,  5.9228e-01,  ..., -3.3003e-01,\n",
       "             1.7169e-01,  8.2872e-02],\n",
       "           [-6.6427e-02,  9.7299e-02,  6.2008e-01,  ..., -6.1153e-02,\n",
       "             3.9582e-02, -1.7040e-01]]], grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.4329, -0.2267, -0.3499,  ...,  0.3101, -0.0369,  0.3970],\n",
       "           [ 0.3557,  1.1424,  0.2681,  ...,  0.4514,  0.0121,  0.1761],\n",
       "           [ 0.3682, -0.7768,  0.6284,  ..., -0.8441,  0.2238, -0.5461],\n",
       "           ...,\n",
       "           [ 0.9265, -0.7443, -0.0251,  ..., -1.4541,  0.1580, -0.7562],\n",
       "           [ 0.5548, -0.6588, -0.0931,  ...,  0.3123,  0.1596,  0.8165],\n",
       "           [-0.0111, -0.0774,  0.0115,  ...,  0.0144,  0.0382, -0.0397]],\n",
       "  \n",
       "          [[ 0.1794, -0.1822, -0.5852,  ...,  0.2106,  0.1465,  0.5311],\n",
       "           [-0.1062,  0.9858, -0.5933,  ...,  0.0632, -0.3951,  0.1160],\n",
       "           [ 0.5511, -0.4152,  0.8520,  ..., -0.7529,  0.0789, -0.2486],\n",
       "           ...,\n",
       "           [-0.3422, -0.5586,  1.0604,  ...,  0.1639, -0.0678,  0.3397],\n",
       "           [-0.4300, -0.1730,  0.9883,  ..., -0.1619, -0.0397,  0.1466],\n",
       "           [-0.0720,  0.0198,  0.8961,  ...,  0.0836,  0.0242, -0.2987]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.1035, -0.2975, -0.3351,  ..., -0.1152, -0.2534,  0.4347],\n",
       "           [ 0.1829,  0.5061, -0.3230,  ...,  0.1127,  0.1879,  0.3247],\n",
       "           [ 0.5665, -0.6048, -0.0042,  ..., -0.8886,  0.9443, -0.2286],\n",
       "           ...,\n",
       "           [ 1.4219, -0.6142, -0.4686,  ..., -0.8972,  0.5112, -0.5374],\n",
       "           [ 0.3072, -0.0884, -0.0938,  ...,  0.0395,  0.1156,  1.2011],\n",
       "           [-0.0149, -0.0481,  0.0226,  ...,  0.0099,  0.0091, -0.0163]],\n",
       "  \n",
       "          [[-0.0694, -0.4023, -0.4072,  ..., -0.0452,  0.1300,  0.3948],\n",
       "           [-0.1320,  0.5054, -0.6441,  ...,  0.1973, -0.1615,  0.0794],\n",
       "           [ 0.6977, -0.4877,  0.3186,  ..., -0.6530,  0.6202, -0.3662],\n",
       "           ...,\n",
       "           [-0.5801, -0.1741,  0.9494,  ..., -0.2125,  0.0137,  0.0151],\n",
       "           [-0.6023,  0.3901,  0.9862,  ..., -0.2036,  0.2229,  0.1269],\n",
       "           [-0.1491,  0.5630,  0.7520,  ..., -0.0889, -0.0148, -0.2493]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.0931, -0.6245, -0.4515,  ..., -0.2254, -0.4321,  0.4606],\n",
       "           [ 0.1188,  0.3001, -0.6093,  ...,  0.2518, -0.1470,  0.3302],\n",
       "           [ 0.7215, -0.6281, -0.2505,  ..., -0.9207,  0.7655,  0.1561],\n",
       "           ...,\n",
       "           [ 0.8247, -0.4994, -0.8723,  ..., -0.4628,  0.2793, -1.1108],\n",
       "           [-0.1549, -0.0475, -0.1317,  ..., -0.1382, -0.3192,  1.3848],\n",
       "           [ 0.0170, -0.0492, -0.0196,  ..., -0.0079, -0.0204, -0.0429]],\n",
       "  \n",
       "          [[ 0.0858, -0.5215, -0.4578,  ..., -0.0571, -0.0742,  0.4022],\n",
       "           [-0.1208,  0.1800, -0.5249,  ...,  0.4326, -0.0353,  0.1768],\n",
       "           [ 0.8333, -0.1848,  0.3726,  ..., -1.2751,  0.2914, -0.0127],\n",
       "           ...,\n",
       "           [-0.7593, -0.1214,  1.2743,  ..., -0.5992,  0.0624, -0.5173],\n",
       "           [-1.0398,  0.3241,  1.3140,  ..., -0.6458,  0.2507, -0.2749],\n",
       "           [-0.5150,  0.3219,  0.8789,  ..., -0.3468,  0.1125, -0.6942]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 3.8578e-01, -4.0396e-01, -3.3126e-01,  ..., -4.4041e-01,\n",
       "             3.2626e-01,  4.4411e-01],\n",
       "           [-8.0577e-02,  7.3084e-01, -5.4004e-01,  ..., -7.6582e-02,\n",
       "             4.0508e-01, -1.0621e-01],\n",
       "           [ 5.5238e-01, -9.6426e-01, -8.5395e-01,  ..., -1.7935e+00,\n",
       "             1.3080e-01,  1.7950e-01],\n",
       "           ...,\n",
       "           [ 5.2227e-01, -5.2399e-01, -5.1779e-01,  ..., -2.3025e-01,\n",
       "             1.0516e+00, -7.6176e-01],\n",
       "           [ 1.8340e-02, -1.0095e+00, -1.3617e+00,  ..., -6.0771e-01,\n",
       "            -1.2181e-01,  1.3397e+00],\n",
       "           [-4.1435e-03, -5.5663e-02,  5.8508e-04,  ..., -4.5402e-02,\n",
       "            -8.1222e-03, -8.2935e-02]],\n",
       "  \n",
       "          [[-2.3278e-01, -8.3265e-01, -2.3096e-01,  ...,  9.9773e-02,\n",
       "             2.3078e-01,  6.2211e-01],\n",
       "           [-4.3336e-01,  5.1238e-02,  3.1283e-02,  ...,  4.7140e-01,\n",
       "             1.7940e-01, -1.3141e-01],\n",
       "           [ 4.3746e-01,  3.3056e-02, -1.4623e-01,  ..., -1.4311e+00,\n",
       "             2.3873e-02,  2.0831e-01],\n",
       "           ...,\n",
       "           [-6.8284e-01, -1.2475e-01,  1.3066e+00,  ..., -3.1423e-01,\n",
       "             2.8454e-01, -4.2179e-01],\n",
       "           [-9.1895e-01,  5.6773e-01,  1.2368e+00,  ..., -8.2166e-01,\n",
       "             3.9666e-01, -2.1670e-02],\n",
       "           [-5.1682e-01,  6.7241e-01,  7.5468e-01,  ..., -2.1662e-01,\n",
       "             2.6313e-01, -5.6195e-01]]], grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.5349, -0.5559, -0.8378,  ..., -0.5402,  0.2432,  0.4598],\n",
       "           [-0.1875,  0.2651, -0.3064,  ...,  0.1720,  0.1803,  0.2999],\n",
       "           [ 0.7456, -1.0081, -0.5727,  ..., -1.4654,  0.0034,  0.3079],\n",
       "           ...,\n",
       "           [ 0.3957, -0.3766, -0.3507,  ..., -0.0994,  0.9196, -0.4541],\n",
       "           [-0.4083, -0.7635, -1.6738,  ..., -0.5919, -0.6077,  0.9291],\n",
       "           [-0.0171, -0.0580,  0.0375,  ..., -0.0575,  0.0020, -0.1182]],\n",
       "  \n",
       "          [[-0.1180, -0.4729, -0.1260,  ..., -0.2754,  0.2776,  0.4798],\n",
       "           [-0.1863, -0.4061,  0.0224,  ...,  0.2172,  0.2101,  0.2325],\n",
       "           [ 0.2145, -0.3470, -0.3474,  ..., -1.4172, -0.3505,  0.5902],\n",
       "           ...,\n",
       "           [-0.9190, -0.1247,  1.5895,  ..., -0.1305,  0.2053, -0.7220],\n",
       "           [-1.2171,  0.2748,  1.5266,  ..., -0.4478,  0.1067, -0.4070],\n",
       "           [-0.6907,  0.5144,  1.0792,  ..., -0.5112,  0.0090, -1.0224]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.4162, -0.3849, -0.6968,  ...,  0.1140,  0.2900,  0.2265],\n",
       "           [-0.5675,  0.1019, -0.2269,  ...,  0.1101, -0.0879,  0.4500],\n",
       "           [ 0.0755, -0.8534, -0.2617,  ..., -1.3773, -0.3603,  0.2792],\n",
       "           ...,\n",
       "           [ 0.2851, -0.6134, -0.4087,  ..., -0.0704,  0.9785, -0.3710],\n",
       "           [-1.5407, -0.6618, -1.5220,  ..., -0.4761, -0.4785,  0.0111],\n",
       "           [-0.0028, -0.0523,  0.0385,  ..., -0.0587, -0.0225, -0.0428]],\n",
       "  \n",
       "          [[-0.1464, -0.2856,  0.1964,  ..., -0.1826,  0.0854,  0.1509],\n",
       "           [-0.8135,  0.0048,  0.0872,  ..., -0.0189, -0.3457,  0.3261],\n",
       "           [-0.4744, -0.1697,  0.1684,  ..., -1.9087, -0.5399,  0.6522],\n",
       "           ...,\n",
       "           [-1.1741, -0.3691,  1.4682,  ..., -0.6893,  0.1477, -0.9920],\n",
       "           [-1.3533, -0.0503,  1.5004,  ..., -0.9338,  0.3256, -0.5789],\n",
       "           [-0.8585,  0.3058,  1.0184,  ..., -1.1451,  0.1706, -1.1447]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.4297, -0.2913, -0.1526,  ..., -0.1361, -0.3693,  0.1562],\n",
       "           [-0.7788,  0.2669, -0.0377,  ...,  0.1236, -0.1611,  0.2075],\n",
       "           [ 0.0638, -0.7215,  0.0310,  ..., -1.0625, -0.5953,  0.2710],\n",
       "           ...,\n",
       "           [ 0.2395, -1.0630, -0.3147,  ...,  0.1217,  0.9343, -0.5491],\n",
       "           [-1.2937, -0.4745, -1.3307,  ..., -0.0455, -0.5800,  0.0904],\n",
       "           [ 0.0067, -0.0128,  0.0623,  ...,  0.2077, -0.0336, -0.0298]],\n",
       "  \n",
       "          [[-0.2358, -0.4663,  0.3963,  ..., -0.2188,  0.0127,  0.3245],\n",
       "           [-0.9916,  0.1465,  0.4633,  ..., -0.2619, -0.1624,  0.1928],\n",
       "           [-0.7039, -0.4075,  0.1488,  ..., -1.3018, -0.0821,  0.2363],\n",
       "           ...,\n",
       "           [-1.0202, -0.5133,  1.3371,  ..., -0.8758,  0.0095, -0.8482],\n",
       "           [-1.2571, -0.1052,  1.4959,  ..., -1.0640,  0.1867, -0.6020],\n",
       "           [-0.6721,  0.1844,  0.7476,  ..., -1.1700, -0.1103, -1.1704]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.3026, -0.0958, -0.1385,  ..., -0.5303, -0.3595,  0.2100],\n",
       "           [-0.3598,  0.2767, -0.0129,  ..., -0.0770, -0.1717,  0.1340],\n",
       "           [-0.0978, -0.0460,  0.1257,  ..., -0.9623, -0.3431,  0.3794],\n",
       "           ...,\n",
       "           [ 0.2722, -0.7536, -0.3623,  ..., -0.1488,  0.8557,  0.4174],\n",
       "           [-1.1535, -0.2737, -0.7478,  ...,  0.0901, -0.4426,  0.1008],\n",
       "           [ 0.0394,  0.0644, -0.0118,  ...,  0.0417, -0.0295,  0.0201]],\n",
       "  \n",
       "          [[ 0.0746, -0.2766,  0.5372,  ..., -0.4498,  0.1867,  0.3444],\n",
       "           [-0.6058,  0.3278,  0.3944,  ..., -0.2529,  0.0469,  0.2036],\n",
       "           [-0.5024, -0.0885,  0.2957,  ..., -0.8261, -0.0354,  0.2689],\n",
       "           ...,\n",
       "           [-0.9171, -0.3254,  1.3509,  ..., -0.8596,  0.0811, -0.8654],\n",
       "           [-1.0864,  0.0999,  1.4413,  ..., -1.1824,  0.4061, -0.6224],\n",
       "           [-0.4590,  0.3898,  0.9065,  ..., -1.2154,  0.1027, -1.1962]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.0226,  0.2761, -0.0618,  ..., -0.2853,  0.0967,  0.4792],\n",
       "           [-0.1892,  0.4992,  0.0321,  ...,  0.2552,  0.7369,  0.3639],\n",
       "           [ 0.3843,  0.3922,  0.3404,  ..., -0.5702,  0.0156,  0.5143],\n",
       "           ...,\n",
       "           [ 0.1358, -0.2267, -0.5335,  ..., -0.2148,  0.4676,  0.4313],\n",
       "           [-0.5522,  0.2536, -0.9563,  ...,  0.3199, -0.0641,  0.0080],\n",
       "           [ 0.5254,  0.3072,  0.0570,  ...,  0.1094, -0.3232,  0.1570]],\n",
       "  \n",
       "          [[ 0.0588, -0.0570,  0.3280,  ..., -0.2171,  0.5852,  0.3195],\n",
       "           [-0.4695,  0.3005,  0.2032,  ..., -0.1371, -0.1421, -0.1138],\n",
       "           [-0.1167, -0.0524,  0.2709,  ..., -0.6149, -0.2356,  0.2129],\n",
       "           ...,\n",
       "           [-0.2933, -0.2423,  0.9609,  ..., -0.5961,  0.1268, -0.4727],\n",
       "           [-0.4726, -0.1329,  1.1231,  ..., -0.7122,  0.2877, -0.5646],\n",
       "           [-0.2109, -0.0045,  0.6145,  ..., -0.6507,  0.1599, -0.6883]]],\n",
       "         grad_fn=<AddBackward0>)],\n",
       " tensor([[-0.8593, -0.4016, -0.6181,  ..., -0.5866, -0.7541,  0.9133],\n",
       "         [-0.7191, -0.2396, -0.1139,  ..., -0.0315, -0.6615,  0.7888]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
