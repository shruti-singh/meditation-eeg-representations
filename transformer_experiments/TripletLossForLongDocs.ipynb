{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be006152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "\n",
    "# DL utils\n",
    "import torch;\n",
    "import transformers;\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import TripletMarginLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593d040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c12792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_tok_and_model():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "    train_on_gpu = True\n",
    "    if train_on_gpu:\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def embed_text_batch_using_bert(text_list, aggregation='cls'):\n",
    "    input_ids = torch.tensor(tokenizer.batch_encode_plus(data_batch, pad_to_max_length=True)['input_ids'])\n",
    "    outputs = model(input_ids.to('cuda'))\n",
    "    last_hidden_states = outputs[0].cpu()  # The last hidden-state is the first element of the output tuple\n",
    "    \n",
    "    if aggregation == 'cls':\n",
    "        # return the vec of the CLS token\n",
    "        return last_hidden_states[:,0,:].detach().numpy()\n",
    "    elif aggregation == 'mean':\n",
    "        # return the mean of all token vecs\n",
    "        return last_hidden_states.mean(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc6d81",
   "metadata": {},
   "source": [
    "### Custom Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27b83d",
   "metadata": {},
   "source": [
    "Needs to implement init, len, getitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraQuestionsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.question_tok_triples = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.question_tok_triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.question_tok_triples[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee00f0d",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60e92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLNetwork(nn.Module):\n",
    "    def __init__(self, emb_dim=768):\n",
    "        super(CLNetwork, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca78b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    torch.nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091fa9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum()\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64e6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "\n",
    "model = CLNetwork(768)\n",
    "# model = torch.jit.script(model).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eed56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
