{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Sample script using EEGNet to classify Event-Related Potential (ERP) EEG data\n",
    " from a four-class classification task, using the sample dataset provided in\n",
    " the MNE [1, 2] package:\n",
    "     https://martinos.org/mne/stable/manual/sample_dataset.html#ch-sample-data\n",
    "   \n",
    " The four classes used from this dataset are:\n",
    "     LA: Left-ear auditory stimulation\n",
    "     RA: Right-ear auditory stimulation\n",
    "     LV: Left visual field stimulation\n",
    "     RV: Right visual field stimulation\n",
    "\n",
    " The code to process, filter and epoch the data are originally from Alexandre\n",
    " Barachant's PyRiemann [3] package, released under the BSD 3-clause. A copy of \n",
    " the BSD 3-clause license has been provided together with this software to \n",
    " comply with software licensing requirements. \n",
    " \n",
    " When you first run this script, MNE will download the dataset and prompt you\n",
    " to confirm the download location (defaults to ~/mne_data). Follow the prompts\n",
    " to continue. The dataset size is approx. 1.5GB download. \n",
    " \n",
    " For comparative purposes you can also compare EEGNet performance to using \n",
    " Riemannian geometric approaches with xDAWN spatial filtering [4-8] using \n",
    " PyRiemann (code provided below).\n",
    "\n",
    " [1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck,\n",
    "     L. Parkkonen, M. Hämäläinen, MNE software for processing MEG and EEG data, \n",
    "     NeuroImage, Volume 86, 1 February 2014, Pages 446-460, ISSN 1053-8119.\n",
    "\n",
    " [2] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, \n",
    "     R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data \n",
    "     analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013.\n",
    "\n",
    " [3] https://github.com/alexandrebarachant/pyRiemann. \n",
    "\n",
    " [4] A. Barachant, M. Congedo ,\"A Plug&Play P300 BCI Using Information Geometry\"\n",
    "     arXiv:1409.0107. link\n",
    "\n",
    " [5] M. Congedo, A. Barachant, A. Andreev ,\"A New generation of Brain-Computer \n",
    "     Interface Based on Riemannian Geometry\", arXiv: 1310.8115.\n",
    "\n",
    " [6] A. Barachant and S. Bonnet, \"Channel selection procedure using riemannian \n",
    "     distance for BCI applications,\" in 2011 5th International IEEE/EMBS \n",
    "     Conference on Neural Engineering (NER), 2011, 348-351.\n",
    "\n",
    " [7] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, “Multiclass \n",
    "     Brain-Computer Interface Classification by Riemannian Geometry,” in IEEE \n",
    "     Transactions on Biomedical Engineering, vol. 59, no. 4, p. 920-928, 2012.\n",
    "\n",
    " [8] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, “Classification of \n",
    "     covariance matrices using a Riemannian-based kernel for BCI applications“, \n",
    "     in NeuroComputing, vol. 112, p. 172-178, 2013.\n",
    "\n",
    "\n",
    " Portions of this project are works of the United States Government and are not\n",
    " subject to domestic copyright protection under 17 USC Sec. 105.  Those \n",
    " portions are released world-wide under the terms of the Creative Commons Zero \n",
    " 1.0 (CC0) license.  \n",
    " \n",
    " Other portions of this project are subject to domestic copyright protection \n",
    " under 17 USC Sec. 105.  Those portions are licensed under the Apache 2.0 \n",
    " license.  The complete text of the license governing this material is in \n",
    " the file labeled LICENSE.TXT that is a part of this project's official \n",
    " distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while the default tensorflow ordering is 'channels_last' we set it here\n",
    "# to be explicit in case if the user has changed the default ordering\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & results----------------\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Models-------------------------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "import sklearn.gaussian_process.kernels as kls\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "\n",
    "# General purpose\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(user_split = True):\n",
    "    X_train = None\n",
    "    y_train_medid = None\n",
    "    y_train_subjid = None\n",
    "    X_val = None\n",
    "    y_val_medid = None\n",
    "    y_val_subjid = None\n",
    "    X_test = None\n",
    "    y_test_medid = None\n",
    "    y_test_subjid = None\n",
    "\n",
    "    # user_split: Determines the creation of train/val/test set. In user_split, test/val users are never seen during the train. time_split randomly splits each user's chunks into train/val/test.\n",
    "    if user_split:\n",
    "        data_file_path = '../../data/Meditation/user_based_splits.pkl'\n",
    "    else:\n",
    "        data_file_path = '../../data/Meditation/time_based_splits.pkl'\n",
    "\n",
    "    with open(data_file_path, 'rb') as f:\n",
    "        all_data_splits = pickle.load(f)\n",
    "\n",
    "        X_train = all_data_splits['train']['x']\n",
    "        y_train_medid = all_data_splits['train']['y_med']\n",
    "        y_train_subjid = all_data_splits['train']['y_subj']\n",
    "\n",
    "        X_val = all_data_splits['val']['x']\n",
    "        y_val_medid = all_data_splits['val']['y_med']\n",
    "        y_val_subjid = all_data_splits['val']['y_subj']\n",
    "\n",
    "        X_test = all_data_splits['test']['x']\n",
    "        y_test_medid = all_data_splits['test']['y_med']\n",
    "        y_test_subjid = all_data_splits['test']['y_subj']\n",
    "\n",
    "    return X_train, y_train_medid, y_train_subjid, X_val, y_val_medid, y_val_subjid, X_test, y_test_medid, y_test_subjid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dict = {\n",
    "    'DecisionTree': {\"model\": DecisionTreeClassifier(random_state=42), \"params\": {'max_depth': list(range(2, 16, 3))}},\n",
    "    'RandomForest': {\"model\": RandomForestClassifier(random_state=42),\n",
    "                     \"params\": {'n_estimators': list(range(5, 100, 5)), 'max_depth': list(range(2, 16))}},\n",
    "    'LogisticR_L1': {\"model\": LogisticRegression(random_state=42, max_iter=500),\n",
    "                     \"params\": {'penalty': ['l1'], 'solver': ['liblinear', 'saga']}},\n",
    "    'LogisticR_L2': {\"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "                     \"params\": {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}},\n",
    "    'LogisticR': {\"model\": LogisticRegression(random_state=42, max_iter=500),\n",
    "                  \"params\": {'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}},\n",
    "    'RidgeClf': {\"model\": RidgeClassifier(max_iter=1000), \"params\": {}},\n",
    "    'SVC_linear': {\"model\": SVC(random_state=42), \"params\": {'kernel': ['linear'], \n",
    "                                                             'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'SVC_poly': {\"model\": SVC(random_state=42),\n",
    "                 \"params\": {'kernel': ['poly'], 'degree': [3, 4, 5], 'gamma': ['scale', 'auto'], \n",
    "                            'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'SVC_others': {\"model\": SVC(random_state=42), \"params\": {'kernel': ['rbf', 'sigmoid'], \n",
    "                                                             'gamma': ['scale', 'auto'], \n",
    "                                                             'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'GussianNB': {\"model\": GaussianNB(), \"params\": {}},\n",
    "    'KNN': {\"model\": KNeighborsClassifier(), \"params\": {'n_neighbors': list(range(3, 30))}},\n",
    "    'GaussianProcessClf': {\"model\": GaussianProcessClassifier(random_state=42, kernel=kls.RBF()), \"params\": {}},\n",
    "    'Bagging_SVC': {\"model\": BaggingClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 20)),\n",
    "                                                                            'base_estimator': [SVC(kernel='linear'),\n",
    "                                                                                               SVC(kernel='poly',\n",
    "                                                                                                   degree=3,\n",
    "                                                                                                   gamma='scale')]}},\n",
    "    'BaggingDT': {\"model\": BaggingClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 20)),\n",
    "                                                                          'base_estimator': [\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=2),\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=5),\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=10)]}},\n",
    "    'AdaBoost': {\"model\": AdaBoostClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 20)),\n",
    "                                                                          'base_estimator': [DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=2),\n",
    "                                                                                             DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=5),\n",
    "                                                                                             DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=10)]}},\n",
    "    'ExtraTrees': {\"model\": ExtraTreesClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 105, 30)), \n",
    "                                                                              'max_depth': [2,5,10,15]}},\n",
    "    'MLP_l1': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x,) for x in \n",
    "                                                                                          range(50, 600, 200)], \n",
    "                                                                  'activation': ['logistic', 'tanh', 'relu'],\n",
    "                                                                  'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "                                                                   [True]}},\n",
    "    'MLP_l2': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x, y) for x in \n",
    "                                                                                          range(50, 600, 200) \n",
    "                                                                                          for y in range(50, 360, 200)], \n",
    "                                                                  'activation': ['logistic', 'tanh', 'relu'],\n",
    "                                                                  'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "                                                                                               [True]}},\n",
    "#     'MLP_l3': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x, y, z) for x in \n",
    "#                                                                                           range(50, 600, 100) \n",
    "#                                                                                           for y in range(50, 600, 100)\n",
    "#                                                                                           for z in range(50, 360, 100)], \n",
    "#                                                                   'activation': ['logistic', 'tanh', 'relu'],\n",
    "#                                                                   'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "#                                                                                                [True]}},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_split   = True\n",
    "med_tech_clf = True\n",
    "\n",
    "X_train, y_train_medid, y_train_subjid, X_val, y_val_medid, y_val_subjid, X_test, y_test_medid, y_test_subjid = load_dataset(user_split=user_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking mean across each channel\n",
    "\n",
    "# X_train_list = []\n",
    "# X_val_list = []\n",
    "# X_test_list = []\n",
    "\n",
    "# for i in range(X_train.shape[0]):\n",
    "#     X_train_list.append(X_train[i,:,:].flatten())\n",
    "# X_train_list = np.array(X_train_list)\n",
    "# print(X_train.shape, X_train_list.shape)\n",
    "\n",
    "# for i in range(X_val.shape[0]):\n",
    "#     X_val_list.append(X_val[i,:,:].flatten())\n",
    "# X_val_list = np.array(X_val_list)\n",
    "# print(X_val.shape, X_val_list.shape)\n",
    "\n",
    "# for i in range(X_test.shape[0]):\n",
    "#     X_test_list.append(X_test[i,:,:].flatten())\n",
    "# X_test_list = np.array(X_test_list)\n",
    "# print(X_test.shape, X_test_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2057, 64, 2560) (2057, 64)\n",
      "(631, 64, 2560) (631, 64)\n",
      "(615, 64, 2560) (615, 64)\n"
     ]
    }
   ],
   "source": [
    "X_train_list = []\n",
    "X_val_list = []\n",
    "X_test_list = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_list.append(np.mean(X_train[i,:,:], axis=1))\n",
    "X_train_list = np.array(X_train_list)\n",
    "print(X_train.shape, X_train_list.shape)\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "    X_val_list.append(np.mean(X_val[i,:,:], axis=1))\n",
    "X_val_list = np.array(X_val_list)\n",
    "print(X_val.shape, X_val_list.shape)\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_list.append(np.mean(X_test[i,:,:], axis=1))\n",
    "X_test_list = np.array(X_test_list)\n",
    "print(X_test.shape, X_test_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df = pd.DataFrame(X_train_list, columns=[str(x) for x in range(0, 163840)])\n",
    "# X_val_df = pd.DataFrame(X_val_list, columns=[str(x) for x in range(0, 163840)])\n",
    "# X_test_df = pd.DataFrame(X_test_list, columns=[str(x) for x in range(0, 163840)])\n",
    "\n",
    "# For keeping only 64 channels data\n",
    "X_train_df = pd.DataFrame(X_train_list, columns=[str(x) for x in range(0, 64)])\n",
    "X_val_df = pd.DataFrame(X_val_list, columns=[str(x) for x in range(0, 64)])\n",
    "X_test_df = pd.DataFrame(X_test_list, columns=[str(x) for x in range(0, 64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree 0.9800722840337326 {'max_depth': 11} 0.3090332805071315\n",
      "RandomForest 1.0 {'max_depth': 9, 'n_estimators': 65} 0.26465927099841524\n",
      "LogisticR_L1 0.9995145631067961 {'penalty': 'l1', 'solver': 'liblinear'} 0.4183835182250396\n",
      "LogisticR_L2 0.9995145631067961 {'penalty': 'l2', 'solver': 'liblinear'} 0.41362916006339145\n",
      "LogisticR 0.9995145631067961 {'penalty': 'none', 'solver': 'newton-cg'} 0.3486529318541997\n",
      "RidgeClf 1.0 {} 0.30269413629160064\n",
      "SVC_linear 0.9995145631067961 {'C': 0.5, 'kernel': 'linear'} 0.4215530903328051\n",
      "SVC_poly 0.998542508208726 {'C': 0.5, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'} 0.3090332805071315\n",
      "SVC_others 1.0 {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'} 0.15213946117274169\n",
      "GussianNB 0.6698875581697493 {} 0.24722662440570523\n",
      "KNN 1.0 {'n_neighbors': 3} 0.05705229793977813\n",
      "GaussianProcessClf 1.0 {} 0.19968304278922344\n",
      "Bagging_SVC 1.0 {'base_estimator': SVC(kernel='linear'), 'n_estimators': 25} 0.41996830427892234\n",
      "BaggingDT 0.9985436893203883 {'base_estimator': DecisionTreeClassifier(max_depth=10, random_state=42), 'n_estimators': 25} 0.2329635499207607\n",
      "AdaBoost 1.0 {'base_estimator': DecisionTreeClassifier(max_depth=5, random_state=42), 'n_estimators': 45} 0.19809825673534073\n",
      "ExtraTrees 1.0 {'max_depth': 10, 'n_estimators': 35} 0.23613312202852615\n",
      "MLP_l1 0.9970873786407767 {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (450,), 'solver': 'adam'} 0.329635499207607\n",
      "MLP_l2 0.9985436893203883 {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (450, 250), 'solver': 'adam'} 0.26465927099841524\n",
      "================================================================================\n",
      "SVC(C=0.5, kernel='linear', random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.33       153\n",
      "           1       0.79      1.00      0.88       156\n",
      "           2       0.00      0.00      0.00       156\n",
      "           3       0.04      0.03      0.04       150\n",
      "\n",
      "    accuracy                           0.34       615\n",
      "   macro avg       0.29      0.34      0.31       615\n",
      "weighted avg       0.29      0.34      0.32       615\n",
      "\n",
      "Test acc: 0.34308943089430893\n",
      "Weighted F1 score:  0.3157496539330504\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train_medid, y_train_subjid, X_val, y_val_medid, y_val_subjid, X_test, y_test_medid, y_test_subjid\n",
    "model_results = pd.DataFrame()\n",
    "model_results['Train_Accuracy'] = None\n",
    "model_results['Val_Accuracy'] = None\n",
    "model_results['Test_Accuracy'] = None\n",
    "model_results['best_params'] = None\n",
    "\n",
    "\n",
    "best_clf_ours = None\n",
    "best_clf_val = 0\n",
    "\n",
    "for clf_name, clf in clf_dict.items():\n",
    "    classifier = GridSearchCV(clf['model'], clf['params'], n_jobs=10)\n",
    "    classifier.fit(X_train_df, y_train_medid)\n",
    "    best_model = classifier.best_estimator_\n",
    "    \n",
    "    y_predicted = best_model.predict(X_val_df)\n",
    "    val_acc = accuracy_score(y_val_medid, y_predicted)\n",
    "    \n",
    "    print(clf_name, classifier.best_score_, classifier.best_params_, val_acc)\n",
    "    \n",
    "    if val_acc > best_clf_val:\n",
    "        best_clf_val = val_acc\n",
    "        best_clf_ours = best_model\n",
    "        \n",
    "    y_predicted = best_model.predict(X_test_df)\n",
    "    test_acc = accuracy_score(y_test_medid, y_predicted)\n",
    "    \n",
    "    \n",
    "    model_results.loc[clf_name, ['Train_Accuracy', 'Val_Accuracy', 'Test_Accuracy', 'best_params']] = [classifier.best_score_, val_acc, test_acc, classifier.best_params_]\n",
    "    clsr = classification_report(y_test_medid, y_predicted)\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(best_clf_ours)\n",
    "best_y_hat = best_clf_ours.predict(X_test_df)\n",
    "clsr = classification_report(y_test_medid, best_y_hat)\n",
    "print(clsr)\n",
    "test_acc = accuracy_score(y_test_medid, best_y_hat)\n",
    "print(\"Test acc:\", test_acc )\n",
    "print(\"Weighted F1 score: \", f1_score(y_test_medid, best_y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.980072</td>\n",
       "      <td>0.309033</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>{'max_depth': 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.264659</td>\n",
       "      <td>0.35122</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L1</th>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.418384</td>\n",
       "      <td>0.239024</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L2</th>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.413629</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR</th>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.348653</td>\n",
       "      <td>0.343089</td>\n",
       "      <td>{'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302694</td>\n",
       "      <td>0.182114</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_linear</th>\n",
       "      <td>0.999515</td>\n",
       "      <td>0.421553</td>\n",
       "      <td>0.343089</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>0.998543</td>\n",
       "      <td>0.309033</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 'auto', 'kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_others</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152139</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GussianNB</th>\n",
       "      <td>0.669888</td>\n",
       "      <td>0.247227</td>\n",
       "      <td>0.198374</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057052</td>\n",
       "      <td>0.274797</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199683</td>\n",
       "      <td>0.256911</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging_SVC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419968</td>\n",
       "      <td>0.344715</td>\n",
       "      <td>{'base_estimator': SVC(kernel='linear'), 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingDT</th>\n",
       "      <td>0.998544</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>{'base_estimator': DecisionTreeClassifier(max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198098</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>{'base_estimator': DecisionTreeClassifier(max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236133</td>\n",
       "      <td>0.297561</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_l1</th>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.329635</td>\n",
       "      <td>0.369106</td>\n",
       "      <td>{'activation': 'relu', 'early_stopping': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_l2</th>\n",
       "      <td>0.998544</td>\n",
       "      <td>0.264659</td>\n",
       "      <td>0.323577</td>\n",
       "      <td>{'activation': 'tanh', 'early_stopping': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Train_Accuracy Val_Accuracy Test_Accuracy  \\\n",
       "DecisionTree             0.980072     0.309033      0.341463   \n",
       "RandomForest                  1.0     0.264659       0.35122   \n",
       "LogisticR_L1             0.999515     0.418384      0.239024   \n",
       "LogisticR_L2             0.999515     0.413629      0.346341   \n",
       "LogisticR                0.999515     0.348653      0.343089   \n",
       "RidgeClf                      1.0     0.302694      0.182114   \n",
       "SVC_linear               0.999515     0.421553      0.343089   \n",
       "SVC_poly                 0.998543     0.309033      0.186992   \n",
       "SVC_others                    1.0     0.152139      0.162602   \n",
       "GussianNB                0.669888     0.247227      0.198374   \n",
       "KNN                           1.0     0.057052      0.274797   \n",
       "GaussianProcessClf            1.0     0.199683      0.256911   \n",
       "Bagging_SVC                   1.0     0.419968      0.344715   \n",
       "BaggingDT                0.998544     0.232964      0.414634   \n",
       "AdaBoost                      1.0     0.198098      0.325203   \n",
       "ExtraTrees                    1.0     0.236133      0.297561   \n",
       "MLP_l1                   0.997087     0.329635      0.369106   \n",
       "MLP_l2                   0.998544     0.264659      0.323577   \n",
       "\n",
       "                                                          best_params  \n",
       "DecisionTree                                        {'max_depth': 11}  \n",
       "RandomForest                     {'max_depth': 9, 'n_estimators': 65}  \n",
       "LogisticR_L1                 {'penalty': 'l1', 'solver': 'liblinear'}  \n",
       "LogisticR_L2                 {'penalty': 'l2', 'solver': 'liblinear'}  \n",
       "LogisticR                  {'penalty': 'none', 'solver': 'newton-cg'}  \n",
       "RidgeClf                                                           {}  \n",
       "SVC_linear                             {'C': 0.5, 'kernel': 'linear'}  \n",
       "SVC_poly            {'C': 0.5, 'degree': 3, 'gamma': 'auto', 'kern...  \n",
       "SVC_others               {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}  \n",
       "GussianNB                                                          {}  \n",
       "KNN                                                {'n_neighbors': 3}  \n",
       "GaussianProcessClf                                                 {}  \n",
       "Bagging_SVC         {'base_estimator': SVC(kernel='linear'), 'n_es...  \n",
       "BaggingDT           {'base_estimator': DecisionTreeClassifier(max_...  \n",
       "AdaBoost            {'base_estimator': DecisionTreeClassifier(max_...  \n",
       "ExtraTrees                      {'max_depth': 10, 'n_estimators': 35}  \n",
       "MLP_l1              {'activation': 'relu', 'early_stopping': True,...  \n",
       "MLP_l2              {'activation': 'tanh', 'early_stopping': True,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_split   = False\n",
    "med_tech_clf = True\n",
    "\n",
    "X_train, y_train_medid, y_train_subjid, X_val, y_val_medid, y_val_subjid, X_test, y_test_medid, y_test_subjid = load_dataset(user_split=user_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 64, 2560) (1954, 64)\n",
      "(661, 64, 2560) (661, 64)\n",
      "(688, 64, 2560) (688, 64)\n"
     ]
    }
   ],
   "source": [
    "X_train_list = []\n",
    "X_val_list = []\n",
    "X_test_list = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_list.append(np.mean(X_train[i,:,:], axis=1))\n",
    "X_train_list = np.array(X_train_list)\n",
    "print(X_train.shape, X_train_list.shape)\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "    X_val_list.append(np.mean(X_val[i,:,:], axis=1))\n",
    "X_val_list = np.array(X_val_list)\n",
    "print(X_val.shape, X_val_list.shape)\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_list.append(np.mean(X_test[i,:,:], axis=1))\n",
    "X_test_list = np.array(X_test_list)\n",
    "print(X_test.shape, X_test_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For keeping only 64 channels data\n",
    "X_train_df = pd.DataFrame(X_train_list, columns=[str(x) for x in range(0, 64)])\n",
    "X_val_df = pd.DataFrame(X_val_list, columns=[str(x) for x in range(0, 64)])\n",
    "X_test_df = pd.DataFrame(X_test_list, columns=[str(x) for x in range(0, 64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree 0.9703206767656896 {'max_depth': 14} 0.972768532526475\n",
      "RandomForest 1.0 {'max_depth': 8, 'n_estimators': 65} 0.9969742813918305\n",
      "LogisticR_L1 0.9984641615843662 {'penalty': 'l1', 'solver': 'saga'} 0.9954614220877458\n",
      "LogisticR_L2 0.9989756705357727 {'penalty': 'l2', 'solver': 'newton-cg'} 0.9954614220877458\n",
      "LogisticR 0.9989756705357727 {'penalty': 'none', 'solver': 'sag'} 0.9954614220877458\n",
      "RidgeClf 0.9943734015345269 {} 0.9954614220877458\n",
      "SVC_linear 0.9989756705357727 {'C': 0.5, 'kernel': 'linear'} 0.9969742813918305\n",
      "SVC_poly 0.9969309462915602 {'C': 1.0, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'} 0.9954614220877458\n",
      "SVC_others 0.9994884910485933 {'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'} 0.9984871406959153\n",
      "GussianNB 0.5066614204210111 {} 0.5279878971255674\n",
      "KNN 1.0 {'n_neighbors': 3} 1.0\n",
      "GaussianProcessClf 0.9989769820971868 {} 1.0\n",
      "Bagging_SVC 0.9989756705357727 {'base_estimator': SVC(kernel='linear'), 'n_estimators': 5} 0.9969742813918305\n",
      "BaggingDT 0.9938592694602925 {'base_estimator': DecisionTreeClassifier(max_depth=10, random_state=42), 'n_estimators': 85} 0.9909228441754917\n",
      "AdaBoost 1.0 {'base_estimator': DecisionTreeClassifier(max_depth=5, random_state=42), 'n_estimators': 45} 0.9984871406959153\n",
      "ExtraTrees 1.0 {'max_depth': 10, 'n_estimators': 65} 1.0\n",
      "MLP_l1 0.9984654731457802 {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (450,), 'solver': 'adam'} 0.9954614220877458\n",
      "MLP_l2 0.9979539641943734 {'activation': 'relu', 'early_stopping': True, 'hidden_layer_sizes': (250, 250), 'solver': 'adam'} 0.9969742813918305\n",
      "================================================================================\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       177\n",
      "           1       1.00      1.00      1.00       164\n",
      "           2       1.00      1.00      1.00       176\n",
      "           3       1.00      1.00      1.00       171\n",
      "\n",
      "    accuracy                           1.00       688\n",
      "   macro avg       1.00      1.00      1.00       688\n",
      "weighted avg       1.00      1.00      1.00       688\n",
      "\n",
      "Test acc: 1.0\n",
      "Weighted F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train_medid, y_train_subjid, X_val, y_val_medid, y_val_subjid, X_test, y_test_medid, y_test_subjid\n",
    "model_results_timesplit = pd.DataFrame()\n",
    "model_results_timesplit['Train_Accuracy'] = None\n",
    "model_results_timesplit['Val_Accuracy'] = None\n",
    "model_results_timesplit['Test_Accuracy'] = None\n",
    "model_results_timesplit['best_params'] = None\n",
    "\n",
    "\n",
    "best_clf_ours = None\n",
    "best_clf_val = 0\n",
    "\n",
    "for clf_name, clf in clf_dict.items():\n",
    "    classifier = GridSearchCV(clf['model'], clf['params'], n_jobs=10)\n",
    "    classifier.fit(X_train_df, y_train_medid)\n",
    "    best_model = classifier.best_estimator_\n",
    "    \n",
    "    y_predicted = best_model.predict(X_val_df)\n",
    "    val_acc = accuracy_score(y_val_medid, y_predicted)\n",
    "    \n",
    "    print(clf_name, classifier.best_score_, classifier.best_params_, val_acc)\n",
    "    \n",
    "    if val_acc > best_clf_val:\n",
    "        best_clf_val = val_acc\n",
    "        best_clf_ours = best_model\n",
    "        \n",
    "    y_predicted = best_model.predict(X_test_df)\n",
    "    test_acc = accuracy_score(y_test_medid, y_predicted)\n",
    "    \n",
    "    \n",
    "    model_results_timesplit.loc[clf_name, ['Train_Accuracy', 'Val_Accuracy', 'Test_Accuracy', 'best_params']] = [classifier.best_score_, val_acc, test_acc, classifier.best_params_]\n",
    "    clsr = classification_report(y_test_medid, y_predicted)\n",
    "\n",
    "print(\"================================================================================\")\n",
    "print(best_clf_ours)\n",
    "best_y_hat = best_clf_ours.predict(X_test_df)\n",
    "clsr = classification_report(y_test_medid, best_y_hat)\n",
    "print(clsr)\n",
    "test_acc = accuracy_score(y_test_medid, best_y_hat)\n",
    "print(\"Test acc:\", test_acc )\n",
    "print(\"Weighted F1 score: \", f1_score(y_test_medid, best_y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.970321</td>\n",
       "      <td>0.972769</td>\n",
       "      <td>0.984012</td>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996974</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L1</th>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.99564</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L2</th>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR</th>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>{'penalty': 'none', 'solver': 'sag'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClf</th>\n",
       "      <td>0.994373</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_linear</th>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.996974</td>\n",
       "      <td>0.99564</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>0.996931</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>{'C': 1.0, 'degree': 3, 'gamma': 'auto', 'kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_others</th>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>{'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GussianNB</th>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.527988</td>\n",
       "      <td>0.530523</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClf</th>\n",
       "      <td>0.998977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging_SVC</th>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.996974</td>\n",
       "      <td>0.99564</td>\n",
       "      <td>{'base_estimator': SVC(kernel='linear'), 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingDT</th>\n",
       "      <td>0.993859</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>{'base_estimator': DecisionTreeClassifier(max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>{'base_estimator': DecisionTreeClassifier(max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_l1</th>\n",
       "      <td>0.998465</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.99564</td>\n",
       "      <td>{'activation': 'relu', 'early_stopping': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_l2</th>\n",
       "      <td>0.997954</td>\n",
       "      <td>0.996974</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>{'activation': 'relu', 'early_stopping': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Train_Accuracy Val_Accuracy Test_Accuracy  \\\n",
       "DecisionTree             0.970321     0.972769      0.984012   \n",
       "RandomForest                  1.0     0.996974      0.998547   \n",
       "LogisticR_L1             0.998464     0.995461       0.99564   \n",
       "LogisticR_L2             0.998976     0.995461      0.997093   \n",
       "LogisticR                0.998976     0.995461      0.997093   \n",
       "RidgeClf                 0.994373     0.995461      0.994186   \n",
       "SVC_linear               0.998976     0.996974       0.99564   \n",
       "SVC_poly                 0.996931     0.995461      0.991279   \n",
       "SVC_others               0.999488     0.998487      0.997093   \n",
       "GussianNB                0.506661     0.527988      0.530523   \n",
       "KNN                           1.0          1.0           1.0   \n",
       "GaussianProcessClf       0.998977          1.0           1.0   \n",
       "Bagging_SVC              0.998976     0.996974       0.99564   \n",
       "BaggingDT                0.993859     0.990923      0.991279   \n",
       "AdaBoost                      1.0     0.998487      0.998547   \n",
       "ExtraTrees                    1.0          1.0      0.998547   \n",
       "MLP_l1                   0.998465     0.995461       0.99564   \n",
       "MLP_l2                   0.997954     0.996974      0.997093   \n",
       "\n",
       "                                                          best_params  \n",
       "DecisionTree                                        {'max_depth': 14}  \n",
       "RandomForest                     {'max_depth': 8, 'n_estimators': 65}  \n",
       "LogisticR_L1                      {'penalty': 'l1', 'solver': 'saga'}  \n",
       "LogisticR_L2                 {'penalty': 'l2', 'solver': 'newton-cg'}  \n",
       "LogisticR                        {'penalty': 'none', 'solver': 'sag'}  \n",
       "RidgeClf                                                           {}  \n",
       "SVC_linear                             {'C': 0.5, 'kernel': 'linear'}  \n",
       "SVC_poly            {'C': 1.0, 'degree': 3, 'gamma': 'auto', 'kern...  \n",
       "SVC_others              {'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "GussianNB                                                          {}  \n",
       "KNN                                                {'n_neighbors': 3}  \n",
       "GaussianProcessClf                                                 {}  \n",
       "Bagging_SVC         {'base_estimator': SVC(kernel='linear'), 'n_es...  \n",
       "BaggingDT           {'base_estimator': DecisionTreeClassifier(max_...  \n",
       "AdaBoost            {'base_estimator': DecisionTreeClassifier(max_...  \n",
       "ExtraTrees                      {'max_depth': 10, 'n_estimators': 65}  \n",
       "MLP_l1              {'activation': 'relu', 'early_stopping': True,...  \n",
       "MLP_l2              {'activation': 'relu', 'early_stopping': True,...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_timesplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compneuro",
   "language": "python",
   "name": "compneuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
